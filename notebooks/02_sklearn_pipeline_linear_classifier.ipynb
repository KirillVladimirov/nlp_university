{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import copy\n",
    "import traceback\n",
    "import datetime\n",
    "import joblib\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pymorphy2\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 42\n",
    "    positive_file = \"../data/positive.csv\"\n",
    "    negative_file = \"../data/negative.csv\"\n",
    "    russian_stop_words = \"../data/russian_stop_words.txt\"\n",
    "    english_stop_words = \"../data/english_stop_words.txt\"\n",
    "    test_size = 0.3\n",
    "    \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "init_random_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train_processed_data.csv\", index_col=False)\n",
    "validate = pd.read_csv(\"../data/validate_processed_data.csv\", index_col=False)\n",
    "test = pd.read_csv(\"../data/test_processed_data.csv\", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test = train['text'].values.tolist(), validate['text'].values.tolist(), test['text'].values.tolist()\n",
    "y_train, y_valid, y_test = train['target'].values.tolist(), validate['target'].values.tolist(), test['target'].values.tolist(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['оставаться самый нужный и самый близкие ) весь остальной уходить ) и я только рада ) потому что я никогда сам не понять нужный я человек или нет )',\n",
       " 'такой приятный чувство , когда ты знаешь , что подарить человек и ты на уверить , что он быть рад ! : ) ) теперь ждать новый год ! : )',\n",
       " 'день начинаться с лень вообще ничто делать не хотеть . даже рука шевелить ( ( ( ничто пройти . . .',\n",
       " 'at_user at_user ксюша поход вплотную там суп заняться )',\n",
       " 'at_user с днём рождение at_user , творческий успех ты ! )',\n",
       " '1 вопрос , ответ . ничто лишний . защищать курсач секунда ) )',\n",
       " 'весь , пора отказаться от кофе , а то иначе мой ближний будущее это жёлтый зуб ( (',\n",
       " 'at_user at_user я снова чувствовать как рушиться мой гениальный план . . ( ( ( рахманинааа , виза лишний нет ? : в я срочно ! ! !',\n",
       " 'at_user а он не говорить кто он быть спрашивать ну или что ? просто как бы два группа сразу ( (',\n",
       " 'неделя ад начаться ; ( ( как же не хотеться вставать ( (']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 1, 1, 1, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(ngram_range=(1, 1), min_df=5)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer(norm=\"l2\", smooth_idf=True, use_idf=True)),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', RandomForestClassifier()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "        \"bow__min_df\": [1, 2, 3, 4, 5],\n",
    "        \"bow__ngram_range\": [(1, 1), (1, 2)],\n",
    "        \"tfidf__use_idf\": (True, False),\n",
    "        \"tfidf__smooth_idf\": (True, False),\n",
    "        \"classifier\": [LogisticRegression()],\n",
    "        \"classifier__penalty\": ['l2','l1'],\n",
    "        \"classifier__C\": np.logspace(0, 4, 10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 800 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=20)]: Done 160 tasks      | elapsed:   52.8s\n",
      "[Parallel(n_jobs=20)]: Done 410 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=20)]: Done 760 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=20)]: Done 1210 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=20)]: Done 1760 tasks      | elapsed: 20.4min\n",
      "[Parallel(n_jobs=20)]: Done 2410 tasks      | elapsed: 24.7min\n",
      "[Parallel(n_jobs=20)]: Done 3160 tasks      | elapsed: 29.1min\n",
      "[Parallel(n_jobs=20)]: Done 4000 out of 4000 | elapsed: 33.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: 0.7724441397251937 using {'bow__min_df': 1, 'bow__ngram_range': (1, 2), 'classifier': LogisticRegression(C=2.7825594022071245), 'classifier__C': 2.7825594022071245, 'classifier__penalty': 'l2', 'tfidf__smooth_idf': True, 'tfidf__use_idf': True}\n"
     ]
    }
   ],
   "source": [
    "# grid = GridSearchCV(pipeline, cv=5, param_grid=parameters, verbose=1, n_jobs=20, scoring=[\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"], refit=\"f1\")\n",
    "grid = GridSearchCV(pipeline, cv=5, param_grid=parameters, verbose=1, n_jobs=20, scoring=\"f1\")\n",
    "grid.fit(X_train,y_train)\n",
    "print(f\"Best Model: {grid.best_score_} using {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: 0.7724441397251937 using {'bow__min_df': 1, 'bow__ngram_range': (1, 2), 'classifier': LogisticRegression(C=2.7825594022071245), 'classifier__C': 2.7825594022071245, 'classifier__penalty': 'l2', 'tfidf__smooth_idf': True, 'tfidf__use_idf': True}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Model: {grid.best_score_} using {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.766702669341151\n",
      "\n",
      "\n",
      "confusion matrix: \n",
      " [[16569  5920]\n",
      " [ 4664 18214]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76     22489\n",
      "           1       0.75      0.80      0.77     22878\n",
      "\n",
      "    accuracy                           0.77     45367\n",
      "   macro avg       0.77      0.77      0.77     45367\n",
      "weighted avg       0.77      0.77      0.77     45367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# save best model to current working directory\n",
    "joblib.dump(grid, \"models/02_sklearn_pipeline_linear_classifier.pkl\")\n",
    "# load from file and predict using the best configs found in the CV step\n",
    "model = joblib.load(\"models/02_sklearn_pipeline_linear_classifier.pkl\" )\n",
    "# get predictions from best model above\n",
    "y_preds = model.predict(X_test)\n",
    "print('accuracy score: ', accuracy_score(y_test, y_preds))\n",
    "print('\\n')\n",
    "print('confusion matrix: \\n', confusion_matrix(y_test,y_preds))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7650356758817975"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = model.predict(X_valid)\n",
    "f1_score(y_valid, y_preds, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
