{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import copy\n",
    "import traceback\n",
    "import datetime\n",
    "import joblib\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import time\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext import vocab\n",
    "from torchtext.vocab import Vectors, GloVe\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pymorphy2\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigExperiment:\n",
    "    seed = 42\n",
    "    positive_file = \"../data/positive.csv\"\n",
    "    negative_file = \"../data/negative.csv\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    embed_dim = 300\n",
    "    max_vocab_size = 50_000\n",
    "    batch_size = 256\n",
    "    num_epochs = 30\n",
    "    lr = 1e-2\n",
    "    num_workers = 0\n",
    "    patience = 5\n",
    "    early_stopping_delta = 1e-4\n",
    "    save_dirname = \"models\"\n",
    "    \n",
    "config = ConfigExperiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    \n",
    "init_random_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train_processed_data.csv\", index_col=False)\n",
    "validate = pd.read_csv(\"../data/validate_processed_data.csv\", index_col=False)\n",
    "test = pd.read_csv(\"../data/test_processed_data.csv\", index_col=False)\n",
    "\n",
    "tokenize = lambda x: str(x).split()\n",
    "TEXT = data.Field(sequential=True, tokenize=tokenize, batch_first=True)\n",
    "LABEL = data.Field(sequential=False, use_vocab=False, dtype=torch.float)\n",
    "\n",
    "fields = [('text',TEXT), ('label', LABEL)]\n",
    "\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "    path=\"../data/\",\n",
    "    train=\"train_processed_data.csv\",\n",
    "    validation=\"validate_processed_data.csv\",\n",
    "    test=\"test_processed_data.csv\",\n",
    "    format=\"csv\",\n",
    "    fields=fields,\n",
    "    skip_header=True)\n",
    "\n",
    "TEXT.build_vocab(train_data, min_freq=2)\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    sort_key = lambda x: x.text,\n",
    "    batch_size=config.batch_size,\n",
    "    device=config.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Скачать и рапаковать предобученные веса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from zipfile import ZipFile\n",
    "# import wget\n",
    "\n",
    "# model_url = 'http://vectors.nlpl.eu/repository/11/187.zip'\n",
    "# wget.download(model_url)\n",
    "# with ZipFile('187.zip', 'r') as zipObj:\n",
    "#    # Extract all the contents of zip file in different directory\n",
    "#    zipObj.extractall('187')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Составить матрицу предобученных весов для словаря "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33041, 300])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model = gensim.models.KeyedVectors.load('187/model.model')\n",
    "numpy_embeddings = np.zeros(shape=[len(TEXT.vocab), config.embed_dim],dtype=np.float32)\n",
    "\n",
    "for word in TEXT.vocab.itos:\n",
    "    vector = w2v_model.get_vector(word)\n",
    "    index  = TEXT.vocab.stoi[word]\n",
    "    numpy_embeddings[index] = vector\n",
    "    \n",
    "pretrained_embeddings = torch.Tensor(numpy_embeddings).float()\n",
    "pretrained_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1d(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels = embedding_dim, \n",
    "                      out_channels = n_filters, \n",
    "                      kernel_size = fs)\n",
    "            for fs in filter_sizes\n",
    "        ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.permute(0, 2, 1)\n",
    "        \n",
    "        #embedded = [batch size, emb dim, sent len]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)) for conv in self.convs]\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "        \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "        \n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = config.embed_dim\n",
    "N_FILTERS = 128\n",
    "FILTER_SIZES = [2, 3]\n",
    "OUTPUT_DIM = 1\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN1d(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 10,104,813 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Копирование предобученных весов в модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, verbose=True, mode=\"max\", factor=0.3)\n",
    "\n",
    "model = model.to(config.device)\n",
    "criterion = criterion.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, train_dataloader: DataLoader, valid_dataloader: DataLoader, \n",
    "                 criterion, optimizer, scheduler, config: ConfigExperiment, model_name: str):\n",
    "        self.model = model\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.device = config.device\n",
    "        self.config = config\n",
    "        self.threshold = 0.5\n",
    "        self.model_name = model_name\n",
    "        self.train_metrics = {\n",
    "            'avg_loss': [],\n",
    "            'accuracy': [],\n",
    "            'f1': [],\n",
    "        }\n",
    "        self.valid_metrics = {\n",
    "            'avg_loss': [],\n",
    "            'accuracy': [],\n",
    "            'f1': [],\n",
    "        }\n",
    "        self.counter = 0\n",
    "        self.delta = config.early_stopping_delta\n",
    "      \n",
    "    def run(self):\n",
    "        self.model.to(self.device)\n",
    "        best_valid_loss = float('inf')\n",
    "        best_target_metric = 0\n",
    "\n",
    "        try:\n",
    "            for i_epoch in tqdm(range(self.config.num_epochs), desc='Epochs', total=config.num_epochs, position=1, leave=True):\n",
    "                start_time = time.time()\n",
    "\n",
    "                train_loss, train_outputs, train_targets = self._train()\n",
    "                valid_loss, valid_outputs, valid_targets = self._evaluate()\n",
    "                    \n",
    "                self.train_metrics[\"avg_loss\"].append(train_loss)\n",
    "                self.train_metrics[\"accuracy\"].append(accuracy_score(train_targets, train_outputs.round() > self.threshold))\n",
    "                self.train_metrics[\"f1\"].append(f1_score(train_targets, train_outputs.round() > self.threshold, average=\"macro\"))\n",
    "                \n",
    "                self.valid_metrics[\"avg_loss\"].append(valid_loss)\n",
    "                self.valid_metrics[\"accuracy\"].append(accuracy_score(valid_targets, valid_outputs.round() > self.threshold))\n",
    "                self.valid_metrics[\"f1\"].append(f1_score(valid_targets, valid_outputs.round() > self.threshold, average=\"macro\"))\n",
    "                \n",
    "                end_time = time.time()\n",
    "                epoch_mins, epoch_secs = self._epoch_time(start_time, end_time)\n",
    "                self.print_progress(i_epoch, epoch_mins, epoch_secs)\n",
    "                \n",
    "                self.scheduler.step(self.valid_metrics[\"f1\"][-1])\n",
    "                \n",
    "                if valid_loss < best_valid_loss:\n",
    "                    best_valid_loss = valid_loss\n",
    "                    torch.save(model.state_dict(), f\"{config.save_dirname}/{self.model_name}.pth\")\n",
    "                    \n",
    "                if self.valid_metrics[\"f1\"][-1] > best_target_metric:\n",
    "                    self.counter = 0\n",
    "                    best_target_metric = self.valid_metrics[\"f1\"][-1]\n",
    "                    torch.save(model.state_dict(), f\"{config.save_dirname}/{self.model_name}.pth\")\n",
    "                else:\n",
    "                    self.counter += 1\n",
    "                    \n",
    "                if self.counter > self.config.patience:\n",
    "                    print(\"EarlyStopping\")\n",
    "                    break\n",
    "        except KeyboardInterrupt:\n",
    "            pass\n",
    "        \n",
    "        return self.train_metrics, self.valid_metrics\n",
    "        \n",
    "    def _train(self):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_output = None\n",
    "        epoch_target = None\n",
    "        for i, batch in tqdm(enumerate(self.train_dataloader), desc='Train', total=len(self.train_dataloader), position=2, leave=True):\n",
    "            loss_iten, outputs = self._train_process(batch)\n",
    "            epoch_loss += loss_iten \n",
    "\n",
    "            if epoch_output is None:\n",
    "                epoch_output = outputs.cpu().data\n",
    "            else:\n",
    "                epoch_output = torch.cat((epoch_output, outputs.cpu().data))\n",
    "\n",
    "            if epoch_target is None:\n",
    "                epoch_target = batch.label.cpu().data\n",
    "            else:\n",
    "                epoch_target = torch.cat((epoch_target, batch.label.cpu().data))\n",
    "            \n",
    "        return epoch_loss / len(self.train_dataloader), epoch_output, epoch_target\n",
    "    \n",
    "    def _train_process(self, batch):      \n",
    "        self.optimizer.zero_grad()\n",
    "        outputs = self.model(batch.text).squeeze(1)\n",
    "        loss = self.criterion(outputs, batch.label)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item(), outputs\n",
    "            \n",
    "    def _evaluate(self):\n",
    "        self.model.eval()\n",
    "        epoch_loss = 0\n",
    "        epoch_output = None\n",
    "        epoch_target = None\n",
    "        with torch.no_grad():\n",
    "            for i, batch in tqdm(enumerate(self.valid_dataloader), desc='Valid', total=len(self.valid_dataloader), position=3, leave=True):\n",
    "                outputs = self.model(batch.text).squeeze(1)\n",
    "                loss = criterion(outputs, batch.label)\n",
    "                epoch_loss += loss.item()\n",
    "                \n",
    "                if epoch_output is None:\n",
    "                    epoch_output = outputs.cpu().data\n",
    "                else:\n",
    "                    epoch_output = torch.cat((epoch_output, outputs.cpu().data))\n",
    "\n",
    "                if epoch_target is None:\n",
    "                    epoch_target = batch.label.cpu().data\n",
    "                else:\n",
    "                    epoch_target = torch.cat((epoch_target, batch.label.cpu().data))\n",
    "\n",
    "        return epoch_loss / len(self.valid_dataloader), epoch_output, epoch_target\n",
    " \n",
    "    def _epoch_time(self, start_time, end_time):\n",
    "        elapsed_time = end_time - start_time\n",
    "        elapsed_mins = int(elapsed_time / 60)\n",
    "        elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "        return elapsed_mins, elapsed_secs\n",
    "\n",
    "    def print_progress(self, i_epoch, epoch_mins, epoch_secs):\n",
    "        if type(i_epoch) != str:\n",
    "            i_epoch = i_epoch + 1\n",
    "            print(f\"Epoch: {i_epoch:02} | Time: {epoch_mins}m {epoch_secs}s\")\n",
    "            print(\"Training Results - Average Loss: {:.4f} | accuracy: {:.4f} | f1: {:.4f}\"\n",
    "                .format(\n",
    "                    self.train_metrics['avg_loss'][-1], \n",
    "                    self.train_metrics['accuracy'][-1],\n",
    "                    self.train_metrics['f1'][-1],\n",
    "                ))      \n",
    "        else:\n",
    "            print(f\"Epoch: {i_epoch} | Time: {epoch_mins}m {epoch_secs}s\")\n",
    "        print(\"Evaluating Results - Average Loss: {:.4f} | accuracy: {:.4f} | f1: {:.4f}\"\n",
    "            .format( \n",
    "                self.valid_metrics['avg_loss'][-1],\n",
    "                self.valid_metrics['accuracy'][-1],\n",
    "                self.valid_metrics['f1'][-1],\n",
    "            ))\n",
    "        print()\n",
    "\n",
    "    def set_model(self, model: nn.Module):\n",
    "        self.model = model\n",
    "        \n",
    "    def evaluate(self, dataloader: DataLoader):\n",
    "        self.valid_dataloader = dataloader\n",
    "        self.model.to(self.device)\n",
    "        start_time = time.time()\n",
    "\n",
    "        valid_loss, valid_outputs, valid_targets = self._evaluate()\n",
    "\n",
    "        self.valid_metrics[\"avg_loss\"].append(valid_loss)\n",
    "        self.valid_metrics[\"accuracy\"].append(accuracy_score(valid_targets, valid_outputs.round() > self.threshold))\n",
    "        self.valid_metrics[\"f1\"].append(f1_score(valid_targets, valid_outputs.round() > self.threshold, average=\"macro\"))\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_mins, epoch_secs = self._epoch_time(start_time, end_time)\n",
    "        self.print_progress(\"evaluate\", epoch_mins, epoch_secs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8073d77673de4b7dbfd278f05c66ae5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epochs', max=30.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d19c5ca6e65440b802e22ca041a2f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train', max=532.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4748a6ac0841402998fd9fd1d24e0a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid', max=178.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 01 | Time: 0m 10s\n",
      "Training Results - Average Loss: 0.2643 | accuracy: 0.8613 | f1: 0.8611\n",
      "Evaluating Results - Average Loss: 0.0206 | accuracy: 0.9913 | f1: 0.9913\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "562aa4524c9a41fda6fd9b2080acbdbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train', max=532.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e1a8831aed44bdbd10c32a98304d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid', max=178.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 02 | Time: 0m 10s\n",
      "Training Results - Average Loss: 0.0203 | accuracy: 0.9915 | f1: 0.9915\n",
      "Evaluating Results - Average Loss: 0.0158 | accuracy: 0.9933 | f1: 0.9933\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e61fff26844a27a404fd885ff6db63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train', max=532.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075cd925b16248b9bd65518dc2aa7706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid', max=178.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 03 | Time: 0m 10s\n",
      "Training Results - Average Loss: 0.0147 | accuracy: 0.9936 | f1: 0.9936\n",
      "Evaluating Results - Average Loss: 0.0161 | accuracy: 0.9935 | f1: 0.9935\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41cd35ea192443d8bbece743af90783d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train', max=532.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab4931edd4ce4eb8a1cb52dd0a44774c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid', max=178.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 04 | Time: 0m 10s\n",
      "Training Results - Average Loss: 0.0124 | accuracy: 0.9949 | f1: 0.9949\n",
      "Evaluating Results - Average Loss: 0.0166 | accuracy: 0.9937 | f1: 0.9937\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "018ead9652024296bf05047a42751a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train', max=532.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e2ef367ff40415cae59d7d99ed9339e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid', max=178.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 05 | Time: 0m 10s\n",
      "Training Results - Average Loss: 0.0098 | accuracy: 0.9961 | f1: 0.9961\n",
      "Evaluating Results - Average Loss: 0.0232 | accuracy: 0.9927 | f1: 0.9927\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de55bf3dcd79421c8fafb31a75e8cd1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train', max=532.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5dd5cd981504e68ae06715328dd356e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid', max=178.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 06 | Time: 0m 10s\n",
      "Training Results - Average Loss: 0.0088 | accuracy: 0.9966 | f1: 0.9966\n",
      "Evaluating Results - Average Loss: 0.0175 | accuracy: 0.9938 | f1: 0.9938\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "102034fc284f46e280d2059bcb3c3e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train', max=532.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f7ece2cad54961ab59156291683019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid', max=178.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 07 | Time: 0m 10s\n",
      "Training Results - Average Loss: 0.0073 | accuracy: 0.9972 | f1: 0.9972\n",
      "Evaluating Results - Average Loss: 0.0181 | accuracy: 0.9940 | f1: 0.9940\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b31ce6d5a6494eb544fa2434afa053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train', max=532.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e414a0f72ad44e759600316e5cb79ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid', max=178.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 08 | Time: 0m 10s\n",
      "Training Results - Average Loss: 0.0068 | accuracy: 0.9975 | f1: 0.9975\n",
      "Evaluating Results - Average Loss: 0.0192 | accuracy: 0.9938 | f1: 0.9938\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b344b010cc4ba79d8ee75264fbf323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train', max=532.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ddf35370fa42bb90fdf36acf7fde15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid', max=178.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 09 | Time: 0m 10s\n",
      "Training Results - Average Loss: 0.0059 | accuracy: 0.9979 | f1: 0.9979\n",
      "Evaluating Results - Average Loss: 0.0213 | accuracy: 0.9941 | f1: 0.9941\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273550cf7a284a3caa4a6452aeca983f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train', max=532.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126bfd896c624c7cb372bdbf4c038579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid', max=178.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 10 | Time: 0m 10s\n",
      "Training Results - Average Loss: 0.0051 | accuracy: 0.9983 | f1: 0.9983\n",
      "Evaluating Results - Average Loss: 0.0230 | accuracy: 0.9941 | f1: 0.9941\n",
      "\n",
      "Epoch    10: reducing learning rate of group 0 to 3.0000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bfc682c31af4c0ca89267dbe5a06853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train', max=532.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26a2300756949489c4d68180e0926ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid', max=178.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 11 | Time: 0m 10s\n",
      "Training Results - Average Loss: 0.0032 | accuracy: 0.9989 | f1: 0.9989\n",
      "Evaluating Results - Average Loss: 0.0229 | accuracy: 0.9939 | f1: 0.9939\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756c5cf45b874f00ae51736f42249b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train', max=532.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6dea35df6ed4e768c6cb5343e6adb1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid', max=178.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 12 | Time: 0m 10s\n",
      "Training Results - Average Loss: 0.0023 | accuracy: 0.9993 | f1: 0.9993\n",
      "Evaluating Results - Average Loss: 0.0225 | accuracy: 0.9941 | f1: 0.9941\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71963c9949a8478e9d137e4ef69a39e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train', max=532.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d858cd561d374d119a2c2d3ca6bc7f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid', max=178.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 13 | Time: 0m 10s\n",
      "Training Results - Average Loss: 0.0019 | accuracy: 0.9994 | f1: 0.9994\n",
      "Evaluating Results - Average Loss: 0.0244 | accuracy: 0.9939 | f1: 0.9939\n",
      "\n",
      "Epoch    13: reducing learning rate of group 0 to 9.0000e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d8afd45394460284861f8e3f6aaf6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train', max=532.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f4e6dfb9b64144b57b0a5f38dfbc33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid', max=178.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 14 | Time: 0m 10s\n",
      "Training Results - Average Loss: 0.0016 | accuracy: 0.9995 | f1: 0.9995\n",
      "Evaluating Results - Average Loss: 0.0236 | accuracy: 0.9939 | f1: 0.9939\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520ddcc7d1c74b689be2a70c010b4dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train', max=532.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ed5b92820a4c76a4bdf14868bbc7ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid', max=178.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 15 | Time: 0m 10s\n",
      "Training Results - Average Loss: 0.0013 | accuracy: 0.9996 | f1: 0.9996\n",
      "Evaluating Results - Average Loss: 0.0243 | accuracy: 0.9939 | f1: 0.9939\n",
      "\n",
      "EarlyStopping\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, train_iterator, valid_iterator, criterion, optimizer, scheduler, config, \"05-conv1d-clf\")\n",
    "trainer.run();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd122c7839f84c49a76bf3b77d919844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid', max=532.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: evaluate | Time: 0m 3s\n",
      "Evaluating Results - Average Loss: 0.0020 | accuracy: 0.9993 | f1: 0.9993\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, train_iterator, valid_iterator, criterion, optimizer, scheduler, config, \"05-conv1d-clf\")\n",
    "model.load_state_dict(torch.load(f'{config.save_dirname}/05-conv1d-clf.pth'))\n",
    "trainer.set_model(model)\n",
    "trainer.evaluate(train_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
