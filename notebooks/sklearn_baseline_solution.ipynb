{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import copy\n",
    "import traceback\n",
    "import datetime\n",
    "import joblib\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pymorphy2\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 42\n",
    "    positive_file = \"../data/positive.csv\"\n",
    "    negative_file = \"../data/negative.csv\"\n",
    "    russian_stop_words = \"../data/russian_stop_words.txt\"\n",
    "    english_stop_words = \"../data/english_stop_words.txt\"\n",
    "    test_size = 0.3\n",
    "    \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "init_random_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/preprocessed_text_v1.csv\", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>ttype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>работа полный пиддес каждый закрытие месяц сви...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>коллега сидеть рубиться urban terror долбать в...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>говорят обещаной год ждать</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>желать хороший полёт удачный посадка быть очен...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>обновить какой леший surf работать простоплеер</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  ttype\n",
       "0  работа полный пиддес каждый закрытие месяц сви...      0\n",
       "1  коллега сидеть рубиться urban terror долбать в...      0\n",
       "2                         говорят обещаной год ждать      0\n",
       "3  желать хороший полёт удачный посадка быть очен...      0\n",
       "4     обновить какой леший surf работать простоплеер      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['message'].values.astype('U'), df['ttype'], random_state=config.seed, test_size=config.test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((158783,), (68051,), (158783,), (68051,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.tolist()\n",
    "X_test = X_test.tolist()\n",
    "y_train = y_train.tolist()\n",
    "y_test = y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['luna самый самый любимый рождественский песенка год',\n",
       " 'скачать симс лизин диск прийтись папка картинка поудалять пофига новый накачать',\n",
       " 'появиться ощущение приближаться новое год ёлка радость поставить',\n",
       " 'итак получить несколько зачёт неделя спасть усердно работать приболеть',\n",
       " 'мозг кипеть спин разболеться',\n",
       " 'хороший мотивация мысль стареть успеть',\n",
       " 'равно мой солнышко просто разнообразие должный разный называть',\n",
       " 'хороший учитель найти сложно мы ментор везти',\n",
       " 'оказываться такой сладкое губа мммм forever alone',\n",
       " 'дыы порнососа музыка слушать пытаться сам придумать фанфик']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0, 0, 0, 1, 0, 1, 1]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(ngram_range=(1, 1), min_df=5)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer(norm=\"l2\", smooth_idf=True, use_idf=True)),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', RandomForestClassifier()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n",
    "\n",
    "# this is where we define the values for GridSearchCV to iterate over\n",
    "parameters = {\n",
    "    'bow__min_df': [1, 2, 3, 4, 5],\n",
    "    'bow__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__smooth_idf': (True, False),\n",
    "    'classifier__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "        \"bow__min_df\": [1, 2, 3, 4, 5],\n",
    "        \"bow__ngram_range\": [(1, 1), (1, 2)],\n",
    "        \"tfidf__use_idf\": (True, False),\n",
    "        \"tfidf__smooth_idf\": (True, False),\n",
    "        \"classifier\": [LogisticRegression()],\n",
    "        \"classifier__penalty\": ['l2','l1'],\n",
    "        \"classifier__C\": np.logspace(0, 4, 10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 800 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=20)]: Done 160 tasks      | elapsed:   53.0s\n",
      "[Parallel(n_jobs=20)]: Done 410 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=20)]: Done 760 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=20)]: Done 1210 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=20)]: Done 1760 tasks      | elapsed: 20.0min\n",
      "[Parallel(n_jobs=20)]: Done 2410 tasks      | elapsed: 24.1min\n",
      "[Parallel(n_jobs=20)]: Done 3160 tasks      | elapsed: 28.0min\n",
      "[Parallel(n_jobs=20)]: Done 4000 out of 4000 | elapsed: 32.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: 0.7363690658322289 using {'bow__min_df': 1, 'bow__ngram_range': (1, 2), 'classifier': LogisticRegression(C=2.7825594022071245), 'classifier__C': 2.7825594022071245, 'classifier__penalty': 'l2', 'tfidf__smooth_idf': False, 'tfidf__use_idf': True}\n"
     ]
    }
   ],
   "source": [
    "# grid = GridSearchCV(pipeline, cv=5, param_grid=parameters, verbose=1, n_jobs=20, scoring=[\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"], refit=\"f1\")\n",
    "grid = GridSearchCV(pipeline, cv=5, param_grid=parameters, verbose=1, n_jobs=20, scoring=\"f1\")\n",
    "grid.fit(X_train,y_train)\n",
    "print(f\"Best Model: {grid.best_score_} using {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: 0.7363690658322289 using {'bow__min_df': 1, 'bow__ngram_range': (1, 2), 'classifier': LogisticRegression(C=2.7825594022071245), 'classifier__C': 2.7825594022071245, 'classifier__penalty': 'l2', 'tfidf__smooth_idf': False, 'tfidf__use_idf': True}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Model: {grid.best_score_} using {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.7352867702164553\n",
      "\n",
      "\n",
      "confusion matrix: \n",
      " [[24043  9346]\n",
      " [ 8668 25994]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.72      0.73     33389\n",
      "           1       0.74      0.75      0.74     34662\n",
      "\n",
      "    accuracy                           0.74     68051\n",
      "   macro avg       0.74      0.74      0.74     68051\n",
      "weighted avg       0.74      0.74      0.74     68051\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# save best model to current working directory\n",
    "joblib.dump(grid, \"sklearn_baseline_solution.pkl\")\n",
    "# load from file and predict using the best configs found in the CV step\n",
    "model = joblib.load(\"sklearn_baseline_solution.pkl\" )\n",
    "# get predictions from best model above\n",
    "y_preds = model.predict(X_test)\n",
    "print('accuracy score: ',accuracy_score(y_test, y_preds))\n",
    "print('\\n')\n",
    "print('confusion matrix: \\n',confusion_matrix(y_test,y_preds))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7426644953001342"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = model.predict(X_test)\n",
    "f1_score(y_test, y_preds, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
