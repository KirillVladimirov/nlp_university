{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import copy\n",
    "import traceback\n",
    "import datetime\n",
    "import joblib\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torchtext import data\n",
    "from torchtext import vocab\n",
    "from torchtext.vocab import Vectors, GloVe\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pymorphy2\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigExperiment:\n",
    "    seed = 42\n",
    "    positive_file = \"../data/positive.csv\"\n",
    "    negative_file = \"../data/negative.csv\"\n",
    "    russian_stop_words = \"../data/russian_stop_words.txt\"\n",
    "    english_stop_words = \"../data/english_stop_words.txt\"\n",
    "    test_size = 0.3\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    embed_dim = 100\n",
    "    batch_size = 256\n",
    "    num_epochs = 50\n",
    "    lr = 1e-2\n",
    "    num_workers = 0\n",
    "    patience = 3\n",
    "    early_stopping_delta = 1e-4\n",
    "    save_dirname = \"models\"\n",
    "    \n",
    "config = ConfigExperiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    \n",
    "init_random_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/preprocessed_text_v1.csv\", index_col=False)\n",
    "df.columns = ['text', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>работа полный пиддес каждый закрытие месяц сви...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>коллега сидеть рубиться urban terror долбать в...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>говорят обещаной год ждать</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>желать хороший полёт удачный посадка быть очен...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>обновить какой леший surf работать простоплеер</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  работа полный пиддес каждый закрытие месяц сви...       0\n",
       "1  коллега сидеть рубиться urban terror долбать в...       0\n",
       "2                         говорят обещаной год ждать       0\n",
       "3  желать хороший полёт удачный посадка быть очен...       0\n",
       "4     обновить какой леший surf работать простоплеер       0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source, test_source = train_test_split(df, random_state=config.seed, test_size=config.test_size)\n",
    "train_source.to_csv(\"../data/train_processed_data.csv\", index=False)\n",
    "test_source.to_csv(\"../data/test_processed_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество обучающих текстов 158783\n",
      "Количество тестовых текстов 68051\n"
     ]
    }
   ],
   "source": [
    "print('Количество обучающих текстов', len(train_source['text']))\n",
    "print('Количество тестовых текстов', len(test_source['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "работа полный пиддес каждый закрытие месяц свихнуться\n",
      "Метка 0\n"
     ]
    }
   ],
   "source": [
    "print(train_source['text'][0].strip())\n",
    "print('Метка', train_source['target'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = train_source['text'].tolist()\n",
    "test_tokenized = test_source['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['luna самый самый любимый рождественский песенка год',\n",
       " 'скачать симс лизин диск прийтись папка картинка поудалять пофига новый накачать',\n",
       " 'появиться ощущение приближаться новое год ёлка радость поставить',\n",
       " 'итак получить несколько зачёт неделя спасть усердно работать приболеть',\n",
       " 'мозг кипеть спин разболеться',\n",
       " 'хороший мотивация мысль стареть успеть',\n",
       " 'равно мой солнышко просто разнообразие должный разный называть',\n",
       " 'хороший учитель найти сложно мы ментор везти',\n",
       " 'оказываться такой сладкое губа мммм forever alone',\n",
       " 'дыы порнососа музыка слушать пытаться сам придумать фанфик']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokenized[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'luna', 'год', 'любимый', 'песенка', 'рождественский', 'самый'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_tokenized[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(tokenized_texts, max_size=1000000, max_doc_freq=0.8, min_count=5, pad_word=None):\n",
    "    word_counts = defaultdict(int)\n",
    "    doc_n = 0\n",
    "\n",
    "    # посчитать количество документов, в которых употребляется каждое слово\n",
    "    # а также общее количество документов\n",
    "    for txt in tokenized_texts:\n",
    "        doc_n += 1\n",
    "        unique_text_tokens = set(txt.split())\n",
    "        for token in unique_text_tokens:\n",
    "            word_counts[token] += 1\n",
    "\n",
    "    # убрать слишком редкие и слишком частые слова\n",
    "    word_counts = {word: cnt for word, cnt in word_counts.items()\n",
    "                   if cnt >= min_count and cnt / doc_n <= max_doc_freq}\n",
    "\n",
    "    # отсортировать слова по убыванию частоты\n",
    "    sorted_word_counts = sorted(word_counts.items(),\n",
    "                                reverse=True,\n",
    "                                key=lambda pair: pair[1])\n",
    "\n",
    "    # добавим несуществующее слово с индексом 0 для удобства пакетной обработки\n",
    "    if pad_word is not None:\n",
    "        sorted_word_counts = [(pad_word, 0)] + sorted_word_counts\n",
    "\n",
    "    # если у нас по прежнему слишком много слов, оставить только max_size самых частотных\n",
    "    if len(word_counts) > max_size:\n",
    "        sorted_word_counts = sorted_word_counts[:max_size]\n",
    "\n",
    "    # нумеруем слова\n",
    "    word2id = {word: i for i, (word, _) in enumerate(sorted_word_counts)}\n",
    "\n",
    "    # нормируем частоты слов\n",
    "    word2freq = np.array([cnt / doc_n for _, cnt in sorted_word_counts], dtype='float32')\n",
    "\n",
    "    return word2id, word2freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DF = 0.8\n",
    "MIN_COUNT = 5\n",
    "vocabulary, word_doc_freq = build_vocabulary(train_tokenized, max_doc_freq=MAX_DF, min_count=MIN_COUNT)\n",
    "UNIQUE_WORDS_N = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных токенов 15123\n",
      "[('хотеть', 0), ('весь', 1), ('день', 2), ('мочь', 3), ('такой', 4), ('сегодня', 5), ('очень', 6), ('быть', 7), ('мой', 8), ('просто', 9)]\n"
     ]
    }
   ],
   "source": [
    "print('Количество уникальных токенов', UNIQUE_WORDS_N)\n",
    "print(list(vocabulary.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXd0lEQVR4nO3df7RlZX3f8feH4aegUGVMFWYY7CBxSFs1d4FpYupqNII4QNUoU6tiEJwmaEzVCGob04KBNomJAYNkSTBqQKqRxcgYTGoRjYiAP5YgIR3J4AzaMPxU8AcBvv1j76vH670z595z7j0zPO/XWrPmnv3j2d9n7332d+/n2WfvVBWSpPbsNukAJEmTYQKQpEaZACSpUSYASWqUCUCSGmUCkKRGmQAkqVHNJoAkm5N8L8n9Sf4xyUVJ9pt0XJK0VJpNAL21VbUf8ExgCnj7hOORpCXTegIAoKpuBz4B/AxAklcnuTnJd5LcmuS1g9MnOT7Jl5N8O8nXkxzdD78qyff7q4r7+yuMzQPzbU5yRpKvJbknyZ8l2Xtg/Av7cu9N8rkk/2rGcj+Y5MGBsrcOjNsrye8l+UZ/RXN+kn0Gxq9KUgOxPZzkNf243ZKc3tflriSXJnn8jPl2nxHHO/q/nzMjjpf2079mYNiv9uvzniRXJjlkrm2R5LgkN/Xr4KokT+uHnzsQeyV5oP/7EwPrfnCZz52x7p/WT3NvX/5xA+P2SfL7SW5Lcl+Sz/bDfqzuSY7sP5/Zf763j+H7/fqcju/l/fhn9dvx3iRfSfKcGXW9aDvbs5KsnmMdbU7y3IHPr0ly1Y7m7et1Uv/3nyT56MC4c5L87ySZZb6Lpus883OSf5bk40m29dv340kOHpj28f1+/s1+/GVDrrsF7QezxL4iyV/28d2V5NyBcc9J8shAeY9Mr9ck+yf5836+25K8Pclu/biTBmL+dpJPJTlotuXv7EwAdDsJ8ALgS/2gO4AXAo8DXg28K8kz+2mPBP4ceDNwAPCLwOaB4k6rqv36K4u1syzu5cDzgX8BPJX+qiPJM4ALgdcCTwDeC1yeZK/BUIGz+rKPmVHu2X15TwdWAwcB/3Vg/PS23r+f/zMD414HnAD8W+DJwD3AebPEvl1J9gD+O/CtgWHHA28FXgQs75d78RzzP7Uf94Z+2o3AhiR7VtXgegX41/3nmethrrg2AJ8EntjX90NJDu8n+T3gZ4F/Azwe+C3gkVmK+p/A7dMfquqAPp71wDXT8VXVh/oDwhXAmX2ZbwI+mmT5QHm7AefMsT0X2xuBf9kfzJ4NnAy8qmZ/NswjzH2s2A34M+AQYCXwPeDcgfEfAB4DHEG37t8FO1x3Y9kPkiwDPg7cBqyi+05cMiP22wfK+8bAuD8G9geeQve9eCXdsWDaNf08TwR+APzmHOtnp9Z6Argsyb3AZ4FPA+8EqKorqurr1fk03YHj2f08JwMXVtVfV9UjVXV7Vf3dPJZ5blVtqaq7gbOAdf3wU4H3VtW1VfVwVb2fbsd61sC8+wAPziywP2s7FfjNqrq7qr7T1+XEgcn2BB6pqodniWk98Laq2lpVPwDeAbwkA2f9Q3otcC3w9zPK/t2qurmqHurjenpmvwp4GXBFv27/ie7AvA/dgXkUzwL2A86uqger6lN0B4Z1/VndrwK/0W/Lh6vqc/16+KEkL6RLwH8z5DL/I7Cxqjb2+8lfA9fTnWhM25NZtudSqKrvAq8A/gD4IPC6qto6x+TfAJ6dgavVgXLuqqqPVtV3+/3uLLoDJkmeRJfY1lfVPVX1T/33aUfGtR8cSXdC8+aqeqCqvl9Vnx0YP+v67xPHicAZVfWdqtoM/D7d+pppt/7fXfOMbafQegI4oT8TOaSqfq2qvgeQ5Jgkn09yd58gXgAc2M+zAvj6CMvcMvD3bXQ7KHRnUG/sL3nv7Ze7YmA8wD8Hts1S5nK6s6wbBub9q374tMfTndnP5hDgYwPz3gw8DPzUwDR3Dox/6cwCkjyW7sz5v8xS9h8NzHs33YF0tkvmJ9OtEwCq6hG69TXs5fW7B5Zz2Yxyt/TlTbutL/dAYG+2v02XAb9LV79hHQL8yozt+QvAkwam2d42AfhiP++tSd44Y9xlA+W+e57zAlBV1wK30m2PS7cTx3nA94F/7Jf3H6ZHJHlMkvf2zSTfBq4GDugPoiuAu6tqe3Wczaj7wbQVwG39icds5lr/BwJ7DMbAj/aXac/q18W9wKHARfOMbafQegL4CX2Ty0fpzjp+qqoOoLsEnW4b3ULXfLNQKwb+Xgl8c6Dcs/qENP3vMVV1cR/XHnR9FF+Zpcw76S69jxiYd7qpZ9pT+fEz80FbgGNmLHvvvm9k2oHT45j9YPFm4NKqum3G8C3Aa2eUvU9VfW6WMr5Jd+Ckr3Po1tfts0w7m9cPxHjCjHJXTLfh9lb25d5Jd3Db3jZ9FXBLVX1+yDigq/cHZtR736o6e2Ca7W0TgGf2dTkOODPJTw+MO2Ggrq+f57wAJPl1YC+69TNncquqbVX1vH6fOgD4i4HRbwQOB46qqsfRNYlC933ZAjw+yQHbqeNsRt0Ppm0BVm7nSnau9X8n8E+DMfCj/WXa5/t1sTfdFdRF84xtp2AC+El70n0ptgEPJTkG+OWB8e8DXp3kl9J1nh4025drO349ycHpOlnfBny4H/6nwPokR6Wzb5Jj+zNr6Nof/x9dM8KP6c+Q/pSur+KJAH1cz+//XgH8Bj9+VjzofOCs6WaZJMv7tvthPbaP76w5yj4jyRF92fsn+ZU5yrkUOLZft3vQHVx+AMyWLObjWuC7wG8l2SNdZ+xa4JJ+3V0I/EGSJydZluTnZvS9vA04Y57L/CCwNsnz+zL3TtfpeHCS3ZOsp2uW+swOyoHuLHN77fDznrdvZz+TrqnqFXTr5ukLKP+xdCcf9/b79G9Pj6iqb9HdXPGedJ3FeyT5xTnKGTSu/eALdP1RZ/ffp72T/DxAkjV0TX8/8Z3om0kvpftOPLb/Xvxnum36E5PTXS0vn2XcTs8EMEPfjvl6uh3gHrrL3csHxn+BvmMYuI+u72DOu1pm8Rd0fQq30jU7nNmXez1wCl0H2j3AJuAkgHR3RryX7lLzO0nup/tiPTnJ+X25b+nn+Xx/Kf43dGdmAFcCV/Uxz+aP+jp+Msl3gM8DR82jTo8D3j3bpX5VfQw4B7ikj+tG5ujwrKpb6A5If0x3FraW7lbdkdrJ+/nX9su9E3gP8MqBvps3AV8FrqNrojqHH/9ufLyq/u88l7kFmO4A30Z3NvrmvtyT6fah46ebHefwmXR3Bv0t8M6q+to8Qphz3v6M+IN0HdBf6ev2VuADMxLfMP6Qrn3+Trr95q9mjH8F3dn039HdXPGGHRU4rv2gP5Cvpbsp4hvAVuBlSfal+w6+t6rmavp6HfAA3ff0s3Tf2wsHxv9c/z28j+4Gh9PmE9vOIuULYZZMutsSX1NVw3YkTs93ErCqqt4xY/jBwJlVddKYQpTUEK8Adg0PAN+eZfhDdGeskjRvXgEsoYVeAUjSYjABSFKjbAKSpEbN95eei+LAAw+sVatWTToMSdql3HDDDXdW1YJvQd0pEsCqVau4/vqfuL1dkrQdSWb+8HJebAKSpEaZACSpURNNAEnWJrngvvvum2QYktSkiSaAqtpQVafuv//+kwxDkppkE5AkNcoEIEmNMgFIUqNMAJLUqJ3ih2CjWHX6FQued/PZx44xEknatXgFIEmNMgFIUqNMAJLUKBOAJDVqURJAkn2TXJ/khYtRviRpdEMlgCQXJrkjyY0zhh+d5JYkm5KcPjDqLcCl4wxUkjRew14BXAQcPTggyTLgPOAYYA2wLsmaJM8DvgbcMcY4JUljNtTvAKrq6iSrZgw+EthUVbcCJLkEOB7YD9iXLil8L8nGqnpkZplJTgVOBVi5cuVC45ckLdAoPwQ7CNgy8HkrcFRVnQaQ5CTgztkO/gBVdQFwAcDU1JRvppekJbZovwSuqot2NE2StcDa1atXL1YYkqQ5jHIX0O3AioHPB/fDhub7ACRpckZJANcBhyU5NMmewInA5eMJS5K02Ia9DfRi4Brg8CRbk5xcVQ8BpwFXAjcDl1bVTfNZuK+ElKTJGfYuoHVzDN8IbFzowqtqA7BhamrqlIWWIUlaGB8FIUmNmmgCsAlIkiZnognAu4AkaXJsApKkRtkEJEmNsglIkhplE5AkNcomIElqlE1AktQom4AkqVEmAElqlAlAkhplJ7AkNcpOYElqlE1AktQoE4AkNcoEIEmNMgFIUqO8C0iSGuVdQJLUKJuAJKlRJgBJapQJQJIaZQKQpEaZACSpUSYASWqUvwOQpEb5OwBJapRNQJLUKBOAJDXKBCBJjTIBSFKjTACS1CgTgCQ1ygQgSY0yAUhSo0wAktSosSeAJE9Lcn6SjyT5T+MuX5I0HkMlgCQXJrkjyY0zhh+d5JYkm5KcDlBVN1fVeuClwM+PP2RJ0jgMewVwEXD04IAky4DzgGOANcC6JGv6cccBVwAbxxapJGmshkoAVXU1cPeMwUcCm6rq1qp6ELgEOL6f/vKqOgZ4+TiDlSSNz+4jzHsQsGXg81bgqCTPAV4E7MV2rgCSnAqcCrBy5coRwpAkLcQoCWBWVXUVcNUQ010AXAAwNTVV445DkrR9o9wFdDuwYuDzwf2woflCGEmanFESwHXAYUkOTbIncCJw+XwK8IUwkjQ5w94GejFwDXB4kq1JTq6qh4DTgCuBm4FLq+qm+SzcKwBJmpyh+gCqat0cwzcywq2eVbUB2DA1NXXKQsuQJC2Mj4KQpEZNNAHYBCRJkzPRBGAnsCRNjk1AktQom4AkqVE2AUlSo2wCkqRGmQAkqVH2AUhSo+wDkKRG2QQkSY0yAUhSo0wAktQoO4ElqVF2AktSo2wCkqRGmQAkqVEmAElqlJ3AktQoO4ElqVE2AUlSo0wAktQoE4AkNWr3SQcwSatOv2Kk+TeffeyYIpGkpecVgCQ1ygQgSY0yAUhSo/whmCQ1yh+CSVKjbAKSpEaZACSpUSYASWqUCUCSGmUCkKRGmQAkqVEmAElqlAlAkhplApCkRi3K46CTnAAcCzwOeF9VfXIxliNJWrihrwCSXJjkjiQ3zhh+dJJbkmxKcjpAVV1WVacA64GXjTdkSdI4zKcJ6CLg6MEBSZYB5wHHAGuAdUnWDEzy9n68JGknM3QCqKqrgbtnDD4S2FRVt1bVg8AlwPHpnAN8oqq+OFt5SU5Ncn2S67dt27bQ+CVJCzRqJ/BBwJaBz1v7Ya8Dngu8JMn62WasqguqaqqqppYvXz5iGJKk+VqUTuCqejfw7h1Nl2QtsHb16tWLEYYkaTtGvQK4HVgx8PngfthQfB+AJE3OqAngOuCwJIcm2RM4Ebh89LAkSYttPreBXgxcAxyeZGuSk6vqIeA04ErgZuDSqrppHmX6SkhJmpCh+wCqat0cwzcCGxey8KraAGyYmpo6ZSHzS5IWzpfCS1KjfCm8JDVqUW4DbcWq069Y8Lybzz52jJFI0vz5NFBJapR9AJLUKPsAJKlRNgFJUqNsApKkRtkEJEmNsglIkhplApCkRpkAJKlRdgJLUqPsBJakRtkEJEmNMgFIUqNMAJLUKB8HPSE+SlrSpHkXkCQ1yruAJKlR9gFIUqNMAJLUKBOAJDXKBCBJjTIBSFKjTACS1Ch/ByBJjfJ3AJLUKB8FsQvyMRKSxsE+AElqlAlAkhplApCkRpkAJKlRJgBJapR3ATVmlDuIwLuIpEcTrwAkqVEmAElq1NgTQJKnJHlfko+Mu2xJ0vgMlQCSXJjkjiQ3zhh+dJJbkmxKcjpAVd1aVScvRrCSpPEZ9grgIuDowQFJlgHnAccAa4B1SdaMNTpJ0qIZKgFU1dXA3TMGHwls6s/4HwQuAY4fdsFJTk1yfZLrt23bNnTAkqTxGKUP4CBgy8DnrcBBSZ6Q5HzgGUnOmGvmqrqgqqaqamr58uUjhCFJWoix/w6gqu4C1o+7XEnSeI1yBXA7sGLg88H9sKH5QhhJmpxREsB1wGFJDk2yJ3AicPl8CvCFMJI0OUM1ASW5GHgOcGCSrcBvV9X7kpwGXAksAy6sqpvms/Aka4G1q1evnl/U2iX5Ihtp5zJUAqiqdXMM3whsXOjCq2oDsGFqauqUhZYhSVoYHwUhSY2aaAKwE1iSJmeiCcBOYEmaHJuAJKlRNgFJUqNsApKkRtkEJEmNMgFIUqPsA5CkRtkHIEmNsglIkhplApCkRo39hTDz4dNAdz2jPNFzUsvdVZ8k2mKdtbTsA5CkRtkEJEmNMgFIUqNMAJLUKBOAJDXKXwJLUqO8C0iSGmUTkCQ1ygQgSY0yAUhSo0wAktQoE4AkNcoEIEmNMgFIUqN8HLQe9Sb1COtJmuSjpH2M9a7DH4JJUqNsApKkRpkAJKlRJgBJapQJQJIaZQKQpEaZACSpUSYASWqUCUCSGmUCkKRGjf1REEn2Bd4DPAhcVVUfGvcyJEmjG+oKIMmFSe5IcuOM4UcnuSXJpiSn94NfBHykqk4BjhtzvJKkMRm2Cegi4OjBAUmWAecBxwBrgHVJ1gAHA1v6yR4eT5iSpHEbqgmoqq5OsmrG4COBTVV1K0CSS4Djga10SeDLbCfBJDkVOBVg5cqV841b0qNQi09uneQTUEfpBD6IH53pQ3fgPwj4S+DFSf4E2DDXzFV1QVVNVdXU8uXLRwhDkrQQY+8ErqoHgFcPM63vA5CkyRnlCuB2YMXA54P7YUPzfQCSNDmjJIDrgMOSHJpkT+BE4PLxhCVJWmzD3gZ6MXANcHiSrUlOrqqHgNOAK4GbgUur6qb5LDzJ2iQX3HffffONW5I0omHvAlo3x/CNwMaFLryqNgAbpqamTlloGZKkhZnooyC8ApCkyfGl8JLUKB8GJ0mNSlVNOgaSbANuW+DsBwJ3jjGcXU3L9W+57mD9W67/dN0PqaoF/5J2p0gAo0hyfVVNTTqOSWm5/i3XHax/y/UfV91tApKkRpkAJKlRj4YEcMGkA5iwluvfct3B+rdc/7HUfZfvA5AkLcyj4QpAkrQAJgBJatROnQDmeOfw4Pi9kny4H3/t4FvLkpzRD78lyfOXMu5xWGjdkzwhyf9Jcn+Sc5c67nEZof7PS3JDkq/2//+7pY59HEao/5FJvtz/+0qSf7/UsY9qlO99P35lv/+/aaliHqcRtv2qJN8b2P7n73BhVbVT/gOWAV8HngLsCXwFWDNjml8Dzu//PhH4cP/3mn76vYBD+3KWTbpOS1T3fYFfANYD5066LhOo/zOAJ/d//wxw+6Trs8T1fwywe//3k4A7pj/vCv9GqfvA+I8A/wt406Trs8TbfhVw43yWtzNfAfzwncNV9SAw/c7hQccD7+///gjwS0nSD7+kqn5QVf8AbOrL21UsuO5V9UBVfRb4/tKFO3aj1P9LVfXNfvhNwD5J9lqSqMdnlPp/t7pHtQPsDexqd3mM8r0nyQnAP9Bt+13RSPWfr505Acz1zuFZp+l3+vuAJww5785slLo/Goyr/i8GvlhVP1ikOBfLSPVPclSSm4CvAusHEsKuYMF1T7If8Bbgd5YgzsUy6r5/aJIvJfl0kmfvaGFjfyewtDNIcgRwDvDLk45lqVXVtcARSZ4GvD/JJ6pqV74iHNY7gHdV1f0LPCHe1X0LWFlVdyX5WeCyJEdU1bfnmmFnvgIY5p3DP5wmye7A/sBdQ867Mxul7o8GI9U/ycHAx4BXVtXXFz3a8RvL9q+qm4H76fpCdhWj1P0o4H8k2Qy8AXhrktMWO+AxW3D9+ybvuwCq6ga6voSnbm9hO3MCGOadw5cDr+r/fgnwqep6Qy4HTux7yw8FDgO+sERxj8ModX80WHD9kxwAXAGcXlV/u2QRj9co9T+0PyiQ5BDgp4HNSxP2WCy47lX17KpaVVWrgD8E3llVu9qdcKNs++VJlgEkeQrdce/W7S5t0r3eO+gRfwHw93SZ7G39sP8GHNf/vTddb/8mugP8UwbmfVs/3y3AMZOuyxLXfTNwN93Z31Zm3EWwK/xbaP2BtwMPAF8e+PfESddnCev/CroO0C8DXwROmHRdlqruM8p4B7vgXUAjbvsXz9j2a3e0LB8FIUmN2pmbgCRJi8gEIEmNMgFIUqNMAJLUKBOAJDXKBCBJjTIBSFKj/j/F2Rzwyy8TxwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(word_doc_freq, bins=20)\n",
    "plt.title('Распределение относительных частот слов')\n",
    "plt.yscale('log');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_texts(tokenized_texts, word2id, word2freq, scale=True):\n",
    "    # считаем количество употреблений каждого слова в каждом документе\n",
    "    result = scipy.sparse.dok_matrix((len(tokenized_texts), len(word2id)), dtype='float32')\n",
    "    for text_i, text in enumerate(tokenized_texts):\n",
    "        for token in text:\n",
    "            if token in word2id:\n",
    "                result[text_i, word2id[token]] += 1\n",
    "\n",
    "    # учитываем всю информацию, которая у нас есть:\n",
    "    # частоту слова в документе и частоту слова в корпусе\n",
    "    result = result.tocsr()\n",
    "    result = result.multiply(1 / result.sum(1))  # разделить каждую строку на её длину\n",
    "    result = result.multiply(1 / word2freq)  # разделить каждый столбец на вес слова\n",
    "\n",
    "    if scale:\n",
    "        result = result.tocsc()\n",
    "        result -= result.min()\n",
    "        result /= (result.max() + 1e-6)\n",
    "\n",
    "    return result.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTORIZATION_MODE = 'tfidf'\n",
    "train_vectors = vectorize_texts(train_tokenized, vocabulary, word_doc_freq, mode=VECTORIZATION_MODE)\n",
    "test_vectors = vectorize_texts(test_tokenized, vocabulary, word_doc_freq, mode=VECTORIZATION_MODE)\n",
    "\n",
    "print('Размерность матрицы признаков обучающей выборки', train_vectors.shape)\n",
    "print('Размерность матрицы признаков тестовой выборки', train_vectors.shape)\n",
    "print()\n",
    "print('Количество ненулевых элементов в обучающей выборке', train_vectors.nnz)\n",
    "print('Процент заполненности матрицы признаков {:.2f}%'.format(train_vectors.nnz * 100 / (train_vectors.shape[0] * train_vectors.shape[1])))\n",
    "print()\n",
    "print('Количество ненулевых элементов в обучающей выборке', test_vectors.nnz)\n",
    "print('Процент заполненности матрицы признаков {:.2f}%'.format(test_vectors.nnz * 100 / (test_vectors.shape[0] * test_vectors.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params_number(model):\n",
    "    return sum(t.numel() for t in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
