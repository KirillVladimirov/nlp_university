{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import copy\n",
    "import traceback\n",
    "import datetime\n",
    "import joblib\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import time\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torchtext import data\n",
    "from torchtext import vocab\n",
    "from torchtext.vocab import Vectors, GloVe\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pymorphy2\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigExperiment:\n",
    "    seed = 42\n",
    "    positive_file = \"../data/positive.csv\"\n",
    "    negative_file = \"../data/negative.csv\"\n",
    "    russian_stop_words = \"../data/russian_stop_words.txt\"\n",
    "    english_stop_words = \"../data/english_stop_words.txt\"\n",
    "    test_size = 0.3\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    embed_dim = 100\n",
    "    batch_size = 256\n",
    "    num_epochs = 50\n",
    "    lr = 1e-2\n",
    "    num_workers = 0\n",
    "    patience = 3\n",
    "    early_stopping_delta = 1e-4\n",
    "    save_dirname = \"models\"\n",
    "    \n",
    "config = ConfigExperiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    \n",
    "init_random_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/preprocessed_text_v1.csv\", index_col=False)\n",
    "df.columns = ['text', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>работа полный пиддес каждый закрытие месяц сви...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>коллега сидеть рубиться urban terror долбать в...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>говорят обещаной год ждать</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>желать хороший полёт удачный посадка быть очен...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>обновить какой леший surf работать простоплеер</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  работа полный пиддес каждый закрытие месяц сви...       0\n",
       "1  коллега сидеть рубиться urban terror долбать в...       0\n",
       "2                         говорят обещаной год ждать       0\n",
       "3  желать хороший полёт удачный посадка быть очен...       0\n",
       "4     обновить какой леший surf работать простоплеер       0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225060</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225062</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225227</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225274</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226015</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>809 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       text  target\n",
       "118     NaN       0\n",
       "1303    NaN       0\n",
       "1370    NaN       0\n",
       "2152    NaN       0\n",
       "2209    NaN       0\n",
       "...     ...     ...\n",
       "225060  NaN       1\n",
       "225062  NaN       1\n",
       "225227  NaN       1\n",
       "225274  NaN       1\n",
       "226015  NaN       1\n",
       "\n",
       "[809 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize = lambda x: x.split()\n",
    "t = df[df['text'].map(str) == 'nan']\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(t.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                226025\n",
       "unique                                               207965\n",
       "top       офигенный день день позитив бегать идиот целый...\n",
       "freq                                                    156\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, random_state=config.seed, test_size=config.test_size)\n",
    "train_df.to_csv(\"../data/train_processed_data.csv\", index=False)\n",
    "test_df.to_csv(\"../data/test_processed_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = lambda x: str(x).split()\n",
    "TEXT = data.Field(sequential=True, tokenize=tokenize, include_lengths=True, batch_first=True)\n",
    "LABEL = data.LabelField(batch_first=True, dtype=torch.float)\n",
    "\n",
    "fields = [('text',TEXT), ('label', LABEL)]\n",
    "\n",
    "# train_data, valid_data = data.TabularDataset.splits(path='../data', \n",
    "#                                             format='csv', \n",
    "#                                             train='train_processed_data.csv', \n",
    "#                                             validation='test_processed_data.csv', \n",
    "#                                             fields=fields, \n",
    "#                                             skip_header=True)\n",
    "\n",
    "# TEXT.build_vocab(train_data, vectors=GloVe(name='6B', dim=300))\n",
    "# LABEL.build_vocab(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, df, fields, is_test=False, **kwargs):\n",
    "        examples = []\n",
    "        for i, row in df.iterrows():\n",
    "            label = row.target if not is_test else None\n",
    "            text = row.text\n",
    "            examples.append(data.Example.fromlist([text, label], fields))\n",
    "\n",
    "        super().__init__(examples, fields, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_key(ex):\n",
    "        return len(ex.text)\n",
    "\n",
    "    @classmethod\n",
    "    def splits(cls, fields, train_df, val_df=None, test_df=None, **kwargs):\n",
    "        train_data, val_data, test_data = (None, None, None)\n",
    "        data_field = fields\n",
    "\n",
    "        if train_df is not None:\n",
    "            train_data = cls(train_df.copy(), data_field, **kwargs)\n",
    "        if val_df is not None:\n",
    "            val_data = cls(val_df.copy(), data_field, **kwargs)\n",
    "        if test_df is not None:\n",
    "            test_data = cls(test_df.copy(), data_field, True, **kwargs)\n",
    "\n",
    "        return tuple(d for d in (train_data, val_data, test_data) if d is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.8 s, sys: 168 ms, total: 32 s\n",
      "Wall time: 32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_ds, test_ds = DataFrameDataset.splits(fields, train_df=train_df, val_df=test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.DataFrameDataset"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158217, 67808)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('text', <torchtext.data.field.Field object at 0x7fc94d55f100>), ('label', <torchtext.data.field.LabelField object at 0x7fc94d55fc10>)])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.fields.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchtext.data.example.Example"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = train_ds[0]\n",
    "type(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['жаль', 'какой', 'город']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['ахахааххаа', 'хороший', 'дело', 'самый', 'любимый', 'щекси', 'дэнс', 'мащина'], 'label': 1}\n",
      "<class 'torchtext.data.example.Example'>\n"
     ]
    }
   ],
   "source": [
    "# Lets look at a random example\n",
    "print(vars(train_ds[15]))\n",
    "\n",
    "# Check the type \n",
    "print(type(train_ds[15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_ds.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL.build_vocab(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79462"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(TEXT.vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " '<pad>',\n",
       " 'хотеть',\n",
       " 'весь',\n",
       " 'день',\n",
       " 'мочь',\n",
       " 'такой',\n",
       " 'сегодня',\n",
       " 'очень',\n",
       " 'быть',\n",
       " 'ты',\n",
       " 'один',\n",
       " 'мой',\n",
       " 'просто',\n",
       " 'год',\n",
       " 'хороший',\n",
       " 'человек',\n",
       " 'знать',\n",
       " 'любить',\n",
       " 'завтра']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('хотеть', 8295), ('весь', 7411), ('день', 7012), ('мочь', 6436), ('такой', 6282), ('сегодня', 6124), ('очень', 5371), ('быть', 5167), ('ты', 4976), ('один', 4846)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'хотеть', 'весь', 'день', 'мочь', 'такой', 'сегодня', 'очень', 'быть', 'ты', 'один', 'мой', 'просто', 'год', 'хороший', 'человек', 'знать', 'любить', 'завтра']\n"
     ]
    }
   ],
   "source": [
    "print(list(TEXT.vocab.stoi.keys())[:20]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Text Vocabulary: 79462\n",
      "Label Length: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of Text Vocabulary: \" + str(len(TEXT.vocab)))\n",
    "print(\"Label Length: \" + str(len(LABEL.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    (train_ds, test_ds), \n",
    "    sort_key=lambda x: len(x.text),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_within_batch = True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 25\n",
    "learning_rate = 0.0001\n",
    "\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.4\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token] # padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_net(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        self.rnn = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout)\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        \n",
    "        # text = [sent len, batch size]\n",
    "        embedded = self.embedding(text)\n",
    "        # embedded = [sent len, batch size, emb dim]\n",
    "\n",
    "        #pack sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths, batch_first=True)\n",
    "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
    "#         packed_output, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        #unpack sequence\n",
    "        # output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "\n",
    "        # output = [sent len, batch size, hid dim * num directions]\n",
    "        # output over padding tokens are zero tensors\n",
    "        \n",
    "        # hidden = [num layers * num directions, batch size, hid dim]\n",
    "        # cell = [num layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        # concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
    "        # and apply dropout\n",
    "        \n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        output = self.fc1(hidden)\n",
    "        output = self.dropout(self.fc2(output))\n",
    "        \n",
    "        output = self.sigmoid(output)\n",
    "        \n",
    "        #hidden = [batch size, hid dim * num directions]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_net(INPUT_DIM, \n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT, \n",
    "            PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.9269,  1.4873,  0.9007,  ...,  0.2539,  0.9364,  0.7122],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.4982, -1.2000,  0.1271,  ..., -0.3867,  0.9578, -0.8225],\n",
      "        ...,\n",
      "        [-0.5829,  0.5939, -0.3095,  ..., -2.1681,  2.1054,  0.9226],\n",
      "        [-1.0517, -0.5362, -0.1695,  ...,  2.3034, -0.9964,  0.2445],\n",
      "        [ 0.0448, -1.0326, -0.6188,  ...,  0.6355,  0.1746,  0.9967]])\n"
     ]
    }
   ],
   "source": [
    "#  to initiaise padded to zeros\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "print(model.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device) #CNN to GPU\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        text, text_lengths = batch.text\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(text, text_lengths).squeeze(1)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator):\n",
    "    \n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text, text_lengths = batch.text\n",
    "            predictions = model(text, text_lengths).squeeze(1)\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "            \n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.693 | Train Acc: 50.93%\n",
      "\t Val. Acc: 49.12%\n",
      "\tTrain Loss: 0.681 | Train Acc: 51.84%\n",
      "\t Val. Acc: 49.11%\n",
      "\tTrain Loss: 0.676 | Train Acc: 52.94%\n",
      "\t Val. Acc: 49.56%\n",
      "\tTrain Loss: 0.673 | Train Acc: 54.86%\n",
      "\t Val. Acc: 50.50%\n",
      "\tTrain Loss: 0.670 | Train Acc: 56.24%\n",
      "\t Val. Acc: 51.54%\n",
      "\tTrain Loss: 0.668 | Train Acc: 57.20%\n",
      "\t Val. Acc: 54.54%\n",
      "\tTrain Loss: 0.666 | Train Acc: 58.63%\n",
      "\t Val. Acc: 56.46%\n",
      "\tTrain Loss: 0.664 | Train Acc: 59.15%\n",
      "\t Val. Acc: 56.04%\n",
      "\tTrain Loss: 0.662 | Train Acc: 59.80%\n",
      "\t Val. Acc: 59.33%\n",
      "\tTrain Loss: 0.662 | Train Acc: 60.65%\n",
      "\t Val. Acc: 58.83%\n",
      "\tTrain Loss: 0.660 | Train Acc: 61.23%\n",
      "\t Val. Acc: 61.24%\n",
      "\tTrain Loss: 0.659 | Train Acc: 61.24%\n",
      "\t Val. Acc: 61.61%\n",
      "\tTrain Loss: 0.658 | Train Acc: 61.96%\n",
      "\t Val. Acc: 63.19%\n",
      "\tTrain Loss: 0.657 | Train Acc: 62.53%\n",
      "\t Val. Acc: 63.87%\n",
      "\tTrain Loss: 0.655 | Train Acc: 62.89%\n",
      "\t Val. Acc: 64.60%\n",
      "\tTrain Loss: 0.655 | Train Acc: 63.52%\n",
      "\t Val. Acc: 65.63%\n",
      "\tTrain Loss: 0.655 | Train Acc: 63.80%\n",
      "\t Val. Acc: 66.20%\n",
      "\tTrain Loss: 0.653 | Train Acc: 64.01%\n",
      "\t Val. Acc: 65.51%\n",
      "\tTrain Loss: 0.653 | Train Acc: 64.17%\n",
      "\t Val. Acc: 65.83%\n",
      "\tTrain Loss: 0.652 | Train Acc: 64.34%\n",
      "\t Val. Acc: 66.64%\n",
      "\tTrain Loss: 0.652 | Train Acc: 64.44%\n",
      "\t Val. Acc: 66.69%\n",
      "\tTrain Loss: 0.650 | Train Acc: 64.88%\n",
      "\t Val. Acc: 67.49%\n",
      "\tTrain Loss: 0.650 | Train Acc: 64.85%\n",
      "\t Val. Acc: 68.00%\n",
      "\tTrain Loss: 0.650 | Train Acc: 65.12%\n",
      "\t Val. Acc: 67.18%\n",
      "\tTrain Loss: 0.649 | Train Acc: 65.45%\n",
      "\t Val. Acc: 68.24%\n",
      "time:686.545\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "loss=[]\n",
    "acc=[]\n",
    "val_acc=[]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator)\n",
    "    valid_acc = evaluate(model, valid_iterator)\n",
    "    \n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Acc: {valid_acc*100:.2f}%')\n",
    "    \n",
    "    loss.append(train_loss)\n",
    "    acc.append(train_acc)\n",
    "    val_acc.append(valid_acc)\n",
    "    \n",
    "print(f'time:{time.time()-t:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_net(\n",
       "  (embedding): Embedding(79462, 300, padding_idx=1)\n",
       "  (rnn): LSTM(300, 256, num_layers=2, dropout=0.4, bidirectional=True)\n",
       "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = LogisticRegression(tfidf_train.shape[1], 1)\n",
    "# model.load_state_dict(torch.load(\"models/best_model.pth\"))\n",
    "# torch.save(model.state_dict(), \"models/torch_baseline_logistic_regression.pth\")\n",
    "# model.load_state_dict(torch.load(\"models/torch_baseline_logistic_regression.pth\"))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a9f8b3a5544e538619c812195b39cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0703125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ground_truth = []\n",
    "results_by_batch = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(valid_iterator, total=len(valid_iterator) / config.batch_size):\n",
    "        text, text_lengths = batch.text\n",
    "        batch_pred = model(text, text_lengths).squeeze(1)\n",
    "        results_by_batch.append(batch_pred.detach().cpu().numpy())\n",
    "        ground_truth.append(batch.label.cpu().numpy())\n",
    "y_test = np.concatenate(ground_truth, 0)\n",
    "y_preds = np.concatenate(results_by_batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.6969384143463898\n",
      "\n",
      "\n",
      "confusion matrix: \n",
      " [[29223  5316]\n",
      " [15234 18035]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.85      0.74     34539\n",
      "         1.0       0.77      0.54      0.64     33269\n",
      "\n",
      "    accuracy                           0.70     67808\n",
      "   macro avg       0.71      0.69      0.69     67808\n",
      "weighted avg       0.71      0.70      0.69     67808\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy score: ',accuracy_score(y_test, y_preds.round()))\n",
    "print('\\n')\n",
    "print('confusion matrix: \\n',confusion_matrix(y_test,y_preds.round()))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_preds.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6884571452978254"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_preds.round(), average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = lambda x: str(x).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(sequential=True, \n",
    "                       tokenize=tokenizer, \n",
    "                       include_lengths=True, \n",
    "                       use_vocab=True)\n",
    "\n",
    "LABEL = data.Field(sequential=False, \n",
    "                         use_vocab=False, \n",
    "                         pad_token=None, \n",
    "                         unk_token=None)\n",
    "\n",
    "fields = [('text',TEXT), ('label', LABEL)]\n",
    "\n",
    "trainds, valds = data.TabularDataset.splits(path='../data', \n",
    "                                            format='csv', \n",
    "                                            train='train_processed_data.csv', \n",
    "                                            validation='test_processed_data.csv', \n",
    "                                            fields=fields, \n",
    "                                            skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchtext.data.dataset.TabularDataset"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158783, 68051)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainds), len(valds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('text', <torchtext.data.field.Field object at 0x7fec3c3f4040>), ('label', <torchtext.data.field.Field object at 0x7fec3c3f4430>)])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainds.fields.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchtext.data.example.Example"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = trainds[0]\n",
    "type(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['luna', 'самый', 'самый', 'любимый', 'рождественский', 'песенка', 'год']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab([trainds.text, valds.text], min_freq=3)\n",
    "LABEL.build_vocab(trainds.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29027"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(TEXT.vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " '<pad>',\n",
       " 'хотеть',\n",
       " 'весь',\n",
       " 'день',\n",
       " 'мочь',\n",
       " 'такой',\n",
       " 'сегодня',\n",
       " 'очень',\n",
       " 'быть',\n",
       " 'ты',\n",
       " 'один',\n",
       " 'просто',\n",
       " 'мой',\n",
       " 'год',\n",
       " 'хороший',\n",
       " 'человек',\n",
       " 'знать',\n",
       " 'любить',\n",
       " 'завтра']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('хотеть', 11807), ('весь', 10570), ('день', 9982), ('мочь', 9172), ('такой', 8928), ('сегодня', 8786), ('очень', 7653), ('быть', 7331), ('ты', 7083), ('один', 6912)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'хотеть', 'весь', 'день', 'мочь', 'такой', 'сегодня', 'очень', 'быть', 'ты', 'один', 'просто', 'мой', 'год', 'хороший', 'человек', 'знать', 'любить', 'завтра']\n"
     ]
    }
   ],
   "source": [
    "print(list(TEXT.vocab.stoi.keys())[:20]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Text Vocabulary: 29027\n",
      "Label Length: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of Text Vocabulary: \" + str(len(TEXT.vocab)))\n",
    "print(\"Label Length: \" + str(len(LABEL.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    datasets=(trainds, valds), # specify train and validation Tabulardataset\n",
    "    batch_size=config.batch_size,  # batch size of train and validation\n",
    "    sort_key=lambda x: len(x.text), # on what attribute the text should be sorted\n",
    "    device=config.device, # -1 mean cpu and 0 or None mean gpu\n",
    "    sort_within_batch=True, \n",
    "    repeat=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "621 266\n"
     ]
    }
   ],
   "source": [
    "print(len(train_iterator), len(valid_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.data.batch.Batch'>\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_iterator)) # BucketIterator return a batch object\n",
    "print(type(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 5126,   703,  5329,  ...,   673,   293, 27600],\n",
      "        [ 1912, 22628,    21,  ...,     7,   676,     0],\n",
      "        [ 1206,  1792,   413,  ...,     8,   217,     0],\n",
      "        [  245,  4096,    29,  ...,   545,   272,     0],\n",
      "        [   13,   440,   302,  ..., 14406,    18,     0],\n",
      "        [  767,   490,  9641,  ...,   744,   552,     0]], device='cuda:0'), tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "print(batch.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
      "        1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
      "        1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
      "        0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
      "        0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
      "        1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(batch.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': <torchtext.data.field.Field object at 0x7fec3c3f4040>, 'label': <torchtext.data.field.Field object at 0x7fec3c3f4430>}\n"
     ]
    }
   ],
   "source": [
    "print(batch.dataset.fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Iterator, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextLinearClassifier(\n",
       "  (embedding): EmbeddingBag(29027, 100, mode=mean)\n",
       "  (linear): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TextLinearClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextLinearClassifier, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.linear = nn.Linear(embed_dim, num_class)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text, text_len):\n",
    "        embedded = self.embedding(text)\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_len)\n",
    "        outputs = self.linear(embedded)\n",
    "        y_pred = self.sigmoid(outputs.view(1, -1).squeeze(0))\n",
    "        return y_pred\n",
    "    \n",
    "model = TextLinearClassifier(vocab_size, config.embed_dim, 1)\n",
    "model.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2902801"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Подсчет количества тренеруемых параметров модели\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SparseAdam(model.parameters(), lr=config.lr)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True, mode=\"max\", factor=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, train_dataloader: DataLoader, valid_dataloader: DataLoader, criterion, optimizer, scheduler, config: ConfigExperiment):\n",
    "        self.model = model\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.device = config.device\n",
    "        self.config = config\n",
    "        self.max_train_iterations = 40\n",
    "#         self.max_train_iterations = len(self.train_dataloader)\n",
    "        self.max_valid_iterations = 10\n",
    "#         self.max_valid_iterations = len(self.valid_dataloader)\n",
    "        self.train_metrics = {\n",
    "            'avg_loss': [],\n",
    "            'accuracy': [],\n",
    "            'f1': [],\n",
    "        }\n",
    "        self.valid_metrics = {\n",
    "            'avg_loss': [],\n",
    "            'accuracy': [],\n",
    "            'f1': [],\n",
    "        }\n",
    "        self.counter = 0\n",
    "        self.delta = config.early_stopping_delta\n",
    "      \n",
    "    def run(self):\n",
    "        self.model.to(self.device)\n",
    "        best_valid_loss = float('inf')\n",
    "        best_target_metric = 0\n",
    "\n",
    "        try:\n",
    "            for i_epoch in tqdm(range(self.config.num_epochs), desc='Epochs', total=config.num_epochs, position=1, leave=True):\n",
    "                start_time = time.time()\n",
    "\n",
    "                train_loss, train_outputs, train_targets = self._train()\n",
    "                valid_loss, valid_outputs, valid_targets = self._evaluate()\n",
    "                    \n",
    "                self.train_metrics[\"avg_loss\"].append(train_loss)\n",
    "                self.train_metrics[\"accuracy\"].append(accuracy_score(train_targets, train_outputs.round()))\n",
    "                self.train_metrics[\"f1\"].append(f1_score(train_targets, train_outputs.round(), average=\"macro\"))\n",
    "                \n",
    "                self.valid_metrics[\"avg_loss\"].append(valid_loss)\n",
    "                self.valid_metrics[\"accuracy\"].append(accuracy_score(valid_targets, valid_outputs.round()))\n",
    "                self.valid_metrics[\"f1\"].append(f1_score(valid_targets, valid_outputs.round(), average=\"macro\"))\n",
    "                \n",
    "                end_time = time.time()\n",
    "                epoch_mins, epoch_secs = self._epoch_time(start_time, end_time)\n",
    "                self.print_progress(i_epoch, epoch_mins, epoch_secs)\n",
    "                \n",
    "                self.scheduler.step(self.valid_metrics[\"f1\"][-1])\n",
    "                \n",
    "                if valid_loss < best_valid_loss:\n",
    "                    best_valid_loss = valid_loss\n",
    "                    torch.save(model.state_dict(), f\"{config.save_dirname}/best_model.pth\")\n",
    "                    \n",
    "                if self.valid_metrics[\"f1\"][-1] > best_target_metric:\n",
    "                    self.counter = 0\n",
    "                    best_target_metric = self.valid_metrics[\"f1\"][-1]\n",
    "                    torch.save(model.state_dict(), f\"{config.save_dirname}/best_model.pth\")\n",
    "                else:\n",
    "                    self.counter += 1\n",
    "                    \n",
    "                if self.counter > self.config.patience:\n",
    "                    print(\"EarlyStopping\")\n",
    "                    break\n",
    "        except KeyboardInterrupt:\n",
    "            pass\n",
    "        \n",
    "        return self.train_metrics, self.valid_metrics\n",
    "        \n",
    "    def _train(self):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_output = None\n",
    "        epoch_target = None\n",
    "        for i, batch in tqdm(enumerate(self.train_dataloader), desc='Train', total=self.max_train_iterations, position=2, leave=True):\n",
    "            if i >= self.max_train_iterations:\n",
    "                break\n",
    "                \n",
    "            loss_iten, outputs = self._train_process(batch)\n",
    "            epoch_loss += loss_iten \n",
    "\n",
    "            if epoch_output is None:\n",
    "                epoch_output = outputs.cpu().data\n",
    "            else:\n",
    "                epoch_output = torch.cat((epoch_output, outputs.cpu().data))\n",
    "\n",
    "            if epoch_target is None:\n",
    "                epoch_target = labels.cpu().data\n",
    "            else:\n",
    "                epoch_target = torch.cat((epoch_target, labels.cpu().data))\n",
    "            \n",
    "        return epoch_loss / len(self.train_dataloader), epoch_output, epoch_target\n",
    "    \n",
    "    def _train_process(self, batch):\n",
    "        text, text_len = batch.text\n",
    "        labels = batch.label\n",
    "        \n",
    "#         print(text)\n",
    "#         print(text_len)\n",
    "#         print(labels)\n",
    "#         print(text.shape, labels.shape)\n",
    "        \n",
    "        \n",
    "#         text, labels = text.to(self.device), labels.to(self.device)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        outputs = self.model(text, text_len)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item(), outputs\n",
    "            \n",
    "    def _evaluate(self):\n",
    "        model.eval()\n",
    "        epoch_loss = 0\n",
    "        epoch_output = None\n",
    "        epoch_target = None\n",
    "        with torch.no_grad():\n",
    "            for i, batch in tqdm(enumerate(self.valid_dataloader), desc='Valid', total=self.max_valid_iterations, position=3, leave=True):\n",
    "                if i >= self.max_valid_iterations:\n",
    "                    break\n",
    "                \n",
    "                text, text_len = batch.text\n",
    "                labels = batch.label\n",
    "#                 text, text_lengths = batch.text\n",
    "#                 text, text_lengths = text.to(self.device), text_lengths.to(self.device)\n",
    "#                 labels = batch.label.to(self.device)\n",
    "                outputs = model(text, text_len)\n",
    "                loss = criterion(outputs, labels)\n",
    "                epoch_loss += loss.item()\n",
    "                \n",
    "                if epoch_output is None:\n",
    "                    epoch_output = outputs.cpu().data\n",
    "                else:\n",
    "                    epoch_output = torch.cat((epoch_output, outputs.cpu().data))\n",
    "\n",
    "                if epoch_target is None:\n",
    "                    epoch_target = labels.cpu().data\n",
    "                else:\n",
    "                    epoch_target = torch.cat((epoch_target, labels.cpu().data))\n",
    "\n",
    "        return epoch_loss / len(self.valid_dataloader), epoch_output, epoch_target\n",
    " \n",
    "    def _epoch_time(self, start_time, end_time):\n",
    "        elapsed_time = end_time - start_time\n",
    "        elapsed_mins = int(elapsed_time / 60)\n",
    "        elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "        return elapsed_mins, elapsed_secs\n",
    "\n",
    "    def print_progress(self, i_epoch, epoch_mins, epoch_secs):\n",
    "        i_epoch = i_epoch + 1\n",
    "        print(f\"Epoch: {i_epoch:02} | Time: {epoch_mins}m {epoch_secs}s\")\n",
    "        print(\"Training Results - Average Loss: {:.4f} | accuracy: {:.4f} | f1: {:.4f}\"\n",
    "            .format(\n",
    "                self.train_metrics['avg_loss'][-1], \n",
    "                self.train_metrics['accuracy'][-1],\n",
    "                self.train_metrics['f1'][-1],\n",
    "            ))\n",
    "        print(\"Evaluating Results - Average Loss: {:.4f} | accuracy: {:.4f} | f1: {:.4f}\"\n",
    "            .format( \n",
    "                self.valid_metrics['avg_loss'][-1],\n",
    "                self.valid_metrics['accuracy'][-1],\n",
    "                self.valid_metrics['f1'][-1],\n",
    "            ))\n",
    "        print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19cf76340d644969a70fd90ea4abe8cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epochs', max=50.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0c01dd2b4e4311bea19a08566030cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train', max=40.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected `len(lengths)` to be equal to batch_size, but got 256 (batch_size=100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-4aad49bde668>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-70-6cabfef2c14d>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-70-6cabfef2c14d>\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mloss_iten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_iten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-70-6cabfef2c14d>\u001b[0m in \u001b[0;36m_train_process\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/nlp_university/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-46c76c60afc0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text, text_len)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mpacked_embedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/nlp_university/venv/lib/python3.8/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_packed_sequence_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected `len(lengths)` to be equal to batch_size, but got 256 (batch_size=100)"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, train_iterator, valid_iterator, criterion, optimizer, scheduler, config)\n",
    "trainer.run();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(tfidf_train.shape[1], 1)\n",
    "model.load_state_dict(torch.load(\"models/best_model.pth\"))\n",
    "torch.save(model.state_dict(), \"models/torch_linear_model.pth\")\n",
    "model.load_state_dict(torch.load(\"models/torch_linear_model.pth\"))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_by_batch = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in tqdm(valid_dataloader, total=len(valid_dataset) / config.batch_size):\n",
    "        batch_x = batch_x.to(config.device)\n",
    "        batch_pred = model(batch_x)\n",
    "        results_by_batch.append(batch_pred.detach().cpu().numpy())\n",
    "        \n",
    "y_preds = np.concatenate(results_by_batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy score: ',accuracy_score(y_test, y_preds.round()))\n",
    "print('\\n')\n",
    "print('confusion matrix: \\n',confusion_matrix(y_test,y_preds.round()))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_preds.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, y_preds.round(), average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
