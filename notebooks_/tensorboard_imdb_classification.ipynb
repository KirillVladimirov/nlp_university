{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(tokenize='spacy', tokenizer_language='en_core_web_md')\n",
    "LABEL = data.LabelField(dtype=torch.float)\n",
    "\n",
    "train_data, test_data = datasets.IMDB.splits(text_field=TEXT, label_field=LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n",
      "['It', \"'s\", 'a', 'colorful', 'slasher', 'movie', '.', 'That', \"'s\", 'about', 'it.<br', '/><br', '/>It', 'has', 'the', 'mystery', 'element', 'that', 'SCREAM', 'made', 'so', 'popular', 'in', 'slasher', 'movies', ',', 'but', 'I', 'never', 'care', 'for', 'such', 'things', '.', 'Figuring', 'out', 'who', \"'s\", 'the', 'bad', 'guy', 'is', 'not', 'that', 'interesting', 'considering', 'the', 'clues', 'are', 'all', 'misleading', 'anyway.<br', '/><br', '/>The', 'death', 'scenes', 'were', 'inventive', 'and', 'gorey', ',', 'bringing', 'back', 'memories', 'of', '80', \"'s\", 'horror', 'movies', 'like', 'Friday', 'the', '13th', '.', '<', 'br', '/><br', '/>Another', 'nice', 'thing', 'about', 'this', 'movie', 'is', 'that', 'it', \"'s\", 'hard', 'to', 'pinpoint', 'the', 'surviving', 'girl', ',', 'unlike', 'in', 'SCREAM', 'and', 'IKWYDLS', 'where', 'it', 'was', 'obvious', '.', '<', 'br', '/><br', '/>People', 'who', 'do', \"n't\", 'like', 'slasher', 'movies', 'wo', \"n't\", 'like', 'this', 'movie', '.', 'As', 'simple', 'as', 'that', '.', 'I', 'truly', 'enjoyed', 'it', 'and', 'I', 'plan', 'to', 'watch', 'it', 'again', 'while', 'waiting', 'for', 'more', 'of', 'the', 'same', '.', '<', 'br', '/><br', '/>--MB']\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0])['label'])\n",
    "print(vars(train_data.examples[0])['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "for batch in range(5):\n",
    "    writer.add_text(\"Text batch\", ' '.join(vars(train_data.examples[0])['text']), batch)\n",
    "    writer.add_text(\"Text batch\", ' '.join(vars(train_data.examples[0])['label']), batch)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [06:43, 2.14MB/s]                               \n",
      "100%|█████████▉| 399999/400000 [00:12<00:00, 30948.21it/s]\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(train_data, max_size=2500, vectors=torchtext.vocab.GloVe(name='6B', dim=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is', 'in', 'I', 'it', 'that', '\"', \"'s\", 'this', '-', '/><br', 'was', 'as', 'with', 'movie', 'for', 'film', 'The', 'but', '(', 'on', ')', \"n't\", 'you', 'are', 'not', 'have', 'his', 'be', 'he', 'one', '!', 'by', 'at', 'all', 'an', 'who', 'they', 'from', 'like', 'so', 'her', \"'\", 'or', 'about', 'has', 'It', 'out', 'just', 'do', '?', 'some', 'good', 'more', 'very', 'would', 'up', 'what', 'This', 'there', 'time', 'can', 'when', 'which', 'she', 'had', 'only', 'story', 'if', 'really', 'were', 'their', 'see', 'even', 'no', 'my', 'me', 'does', 'did', 'than', '...', ':', 'much', 'been', 'could', 'get', 'into', 'well', 'will', 'we', 'other', 'people', 'bad', 'because', 'him', 'great', 'made', 'most', 'first', 'make', 'also', 'them', 'way', 'how', '<', 'its', 'br', 'any', 'too', 'movies', '/>The', 'think', 'characters', 'character', 'then', 'films', 'seen', ';', 'But', 'two', 'being', 'plot', 'watch', 'many', 'acting', 'never', 'life', 'And', 'over', 'little', 'know', 'after', 'where', 'show', 'off', 'love', 'best', 'ever', '*', 'better', 'your', 'A', 'end', 'say', 'should', 'scene', 'He', 'There', 'i', 'still', 'scenes', 'In', \"'ve\", 'such', 'here', 'man', 'through', 'something', '/', 'go', 'back', 'these', 'real', 'If', \"'m\", 'those', 'actors', 'thing', 'watching', 'years', 'old', 'work', 'makes', 'find', '--', 'funny', 'though', 'going', 'few', 'actually', 'same', 'before', 'why', 'look', 'lot', 'while', 'director', 'nothing', 'cast', 'part', 'another', '/>I', \"'re\", 'ca', 'want', 'quite', 'got', 'again', 'seems', 'down', '&', 'around', 'pretty', 'fact', 'every', 'things', 'thought', 'enough', 'between', 'take', 'own', 'young', 'original', 'horror', 'long', 'now', 'action', 'give', 'series', 'us', 'world', 'gets', 'must', 'may', 'always', 'right', 'role', 'They', 'least', 'saw', 'new', 'whole', 'comedy', 'point', 'without', 'You', 'interesting', 'times', 'bit', 'both', 'done', 'almost', 'family', 'come', 'big', 'script', 'feel', 'might', 'making', 'far', 'guy', 'minutes', 'performance', 'anything', 'music', 'What', \"'ll\", 'kind', 'am', 'She', 'probably', 'TV', 'last', 'As', 'away', 'woman', 'rather', 'girl', 'found', 'fun', 'since', 'played', 'hard', 'worst', 'That', 'comes', 'course', 'trying', 'believe', 'goes', 'each', 'looking', 'screen', 'looks', 'different', 'anyone', 'set', 'put', 'yet', 'especially', 'our', 'day', 'place', 'book', 'shows', 'reason', 'actor', 'ending', 'sure', 'money', 'DVD', 'sense', '/>This', 'main', \"'d\", 'watched', 'plays', 'having', 'job', 'American', 'When', 'takes', 'seem', '10', 'said', 'worth', 'effects', 'play', 'someone', '2', 'together', 'true', 'So', 'audience', 'himself', 'John', 'version', 'wife', 'beautiful', 'three', 'left', 'half', 'year', 'idea', 'special', 'seeing', 'shot', 'father', 'everything', 'else', 'later', 'during', 'excellent', 'less', 'once', 'nice', 'everyone', 'read', 'high', 'simply', 'One', 'We', 'fan', 'mind', 'used', 'completely', 'help', 'Hollywood', 'Not', 'need', 'let', 'budget', 'short', 'use', 'rest', 'performances', 'For', 'However', 'poor', 'low', 'second', 'try', 'given', 'camera', 'classic', 'top', 'line', 'kids', 'production', 'enjoy', 'until', 'either', 'My', 'home', 'women', 'start', 'tell', 'boring', 'friends', 'couple', 'truly', 'recommend', 'wrong', 'mean', 'All', 'came', 'understand', '..', 'men', 'house', '/>It', 'instead', 'moments', 'night', 'small', 'playing', 'getting', 'along', 'full', 'awful', 'stupid', 'sex', 'video', 'death', 'gives', 'remember', 'doing', 'episode', 'person', 'stars', 'although', 'become', 'keep', 'style', 'often', 'wonderful', 'however', 'black', 'written', 'next', 'felt', 'face', 'name', 'piece', 'lines', 'early', 'supposed', 'school', 'liked', 'human', 'terrible', 'itself', 'dialogue', 'maybe', 'No', 'perfect', 'others', 'star', 'head', 'entire', 'went', 'against', 'sort', 'THE', 'case', 'Even', 'waste', 'live', 'called', 'children', 'problem', 'absolutely', 'definitely', 'title', 'At', 'war', 'entertaining', 'After', 'becomes', 'His', 'friend', 'seemed', 'mother', 'certainly', 'already', 'beginning', 'Well', '\\x96', 'boy', 'worse', 'laugh', 'drama', 'example', 'wanted', 'several', 'picture', 'loved', '3', 'Do', 'based', 'cinema', 'care', 'lives', 'fans', 'turn', 'To', 'hope', 'dead', 'Michael', 'under', 'lost', 'wo', 'direction', 'wants', 'fine', 'lead', 'humor', 'tries', 'quality', 'son', '<br', 'writing', 'works', 'able', 'totally', 'guys', 'enjoyed', 'guess', 'past', 'viewer', 'sound', '1', 'killer', 'turns', 'New', 'finally', 'throughout', 'gave', 'amazing', 'starts', 'side', 'behind', 'heart', 'close', 'favorite', 'evil', 'genre', 'hand', 'history', 'flick', 'town', 'child', '>', 'final', 'Then', 'car', 'Why', 'While', 'game', 'Also', 'How', 'self', 'act', 'parts', 'perhaps', 'white', '....', 'themselves', 'expect', 'today', 'art', 'thinking', 'actress', 'late', 'decent', 'stories', 'feeling', 'voice', 'Of', 'directed', 'myself', 'days', 'hour', 'stuff', 'run', 'says', 'slow', 'took', 'girls', 'etc', 'heard', 'type', 'daughter', 'horrible', 'brilliant', 'matter', 'killed', 'Some', 'kid', 'dark', 'moment', 'fight', 'kill', 'known', 'roles', 'happens', 'involved', 'hit', 'eyes', 'obvious', 'lack', 'writer', 'attempt', 'told', 'extremely', 'particularly', 'Mr.', 'violence', 'including', 'soon', 'James', 'happened', 'leave', 'strong', 'Just', 'group', 'stop', 'sometimes', 'coming', 'complete', 'interest', 'chance', 'experience', 'looked', 'except', 'husband', 'obviously', 'ago', 'happen', 'brother', 'highly', 'shown', 'With', 'wonder', 'score', 'whose', '/>There', 'David', 'number', 'Now', 'career', 'taken', '/>In', 'serious', 'hero', 'age', 'exactly', 'musical', 'English', 'annoying', 'somewhat', 'relationship', 'simple', 'started', 'hours', 'finds', 'opening', 'jokes', 'novel', 'crap', 'released', 'across', 'change', 'alone', 'ends', 'sad', 'usual', 'cinematography', 'female', 'gore', 'level', 'turned', 'yourself', 'shots', 'talking', '/>If', 'despite', 'opinion', 'Robert', 'cut', 'reality', 'light', 'murder', 'documentary', 'ridiculous', 'running', 'save', 'song', 'ones', 'body', 'police', 'saying', 'important', 'living', 'view', 'possible', 'hilarious', 'episodes', 'Man', 'single', 'talent', 'taking', 'huge', 'wish', 'word', '5', 'British', 'events', 'usually', 'middle', 'modern', 'knew', 'tells', 'mostly', 'songs', 'attention', 'comic', 'order', 'cool', 'non', 'local', 'blood', '4', 'call', 'due', 'sequence', 'knows', 'happy', 'thriller', 'room', 'scary', 'disappointed', 'problems', 'Jack', 'cheap', 'Oh', 'easily', 'Paul', 'it.<br', 'sets', 'silly', 'supporting', 'bring', 'class', 'major', 'television', 'country', 'similar', 'strange', 'appears', 'romantic', 'On', 'future', 'clearly', 'words', '/>But', 'George', 'Oscar', 'falls', 'Although', 'needs', 'moving', 'giving', 'predictable', 'OK', 'mention', 'message', 'entertainment', 'feels', 'enjoyable', 'stand', 'fast', 'seriously', 'review', 'Richard', 'near', 'points', 'five', 'four', 'herself', 'hell', 'straight', 'animation', 'York', 'surprised', 'God', 'actual', 'above', 'named', 'theme', 'Lee', 'King', 'nearly', 'none', 'upon', 'within', 'First', 'release', 'sequel', 'talk', 'working', 'ways', 'beyond', 'elements', 'bunch', 'power', 'clear', 'dull', 'effort', 'storyline', 'feature', 'tried', 'typical', 'begins', 'comments', 'showing', 'team', 'means', 'form', 'tale', 'using', 'viewers', 'easy', 'overall', 'figure', 'kept', 'famous', 'Peter', 'dialog', 'hate', 'fall', 'movie.<br', 'realistic', 'sister', 'Maybe', 'rating', 'certain', 'doubt', 'leads', 'soundtrack', 'weak', 'brought', 'editing', 'ten', 'follow', 'material', 'Her', 'fantastic', 'Disney', 'theater', 're', 'whether', 'hear', 'particular', 'viewing', 'Tom', 'among', 'parents', '/>A', 'Unfortunately', 'atmosphere', 'sequences', '$', 'filmed', 'greatest', 'learn', 'period', 'stay', 'America', 'decided', 'film.<br', 'sexual', 'apparently', 'Who', 'eye', '/>And', 'city', 'B', 'basically', 'Yes', 'move', 'Is', 'Japanese', 'reviews', 'stage', '/>As', 'buy', 'premise', 'crime', 'became', 'expected', 'sit', 'subject', 'average', 'suspense', 'deal', 'French', 'From', 'difficult', 'poorly', 'lame', 'minute', 'killing', 'lots', 'mystery', 'add', 'leaves', 'believable', 'nature', 'surprise', 'needed', 'yes', 'Its', 'Joe', 'begin', 'gone', 'meets', 'question', 'possibly', 'NOT', 'somehow', 'write', 'realize', 'forced', '`', 'dramatic', 'emotional', 'These', 'male', 'dance', 'free', 'older', 'Like', 'acted', 'credits', 'interested', 'memorable', 'reading', 'third', 'An', 'directors', 'keeps', 'situation', 'earlier', 'writers', '20', 'forward', 'screenplay', 'season', 'comment', 'footage', 'rent', 'truth', 'wait', 'Jane', 'superb', 'whom', 'die', 'features', 'worked', 'badly', 'open', 'brings', 'nor', 'previous', 'admit', 'romance', 's', 'imagine', 'laughs', 'result', 'meet', 'perfectly', 'creepy', 'weird', 'Most', 'War', 'quickly', 'unique', 'appear', 'ask', 'setting', 'directing', 'personal', 'please', 'society', 'forget', 'rate', 'create', 'cheesy', 'meant', 'development', 'eventually', 'effect', 'towards', 'political', 'background', 'business', 'leading', 'mess', 'present', 'girlfriend', 'Christmas', 'joke', 'powerful', 'check', 'general', 'incredibly', 'various', 'deep', 'portrayed', 'potential', 'fails', 'telling', 'box', 'fighting', 'fantasy', 'pay', 'Here', 'ideas', 'sorry', 'casting', 'hands', 'manages', 'note', 'sounds', 'hot', 'villain', 'deserves', 'front', 'attempts', 'expecting', 'plenty', 'battle', 'Ben', 'crazy', 'shame', 'William', 'total', 'remake', 'talented', 'fairly', 'space', 'cop', 'missing', 'break', 'outside', 'agree', 'copy', 'reasons', 'Scott', 'masterpiece', 'beauty', 'twist', 'indeed', 'miss', 'hardly', 'wrote', 'nudity', 'social', 'success', 'By', 'flat', 'gay', 'Or', 'inside', 'mentioned', 'whatever', 'IMDb', 'anyway', 'married', 'plain', 'dumb', 'monster', 'air', 'cute', 'era', 'recently', 'filmmakers', 'decides', '30', 'crew', '80', 'ended', 'caught', 'Dr.', 'large', 'members', 'missed', 'popular', 'waiting', 'Mary', 'uses', 'wasted', 'created', 'dream', 'familiar', 'sees', 'pace', 'slightly', '/>So', 'lady', 'spent', 'hold', 'rich', 'Bill', 'Star', 'convincing', 'filled', 'produced', 'unless', 'entirely', 'further', 'list', '/>What', 'bored', 'dog', 'intelligent', 'public', 'unfortunately', 'Instead', 'moves', 'pure', 'tension', 'odd', 'zombie', 'laughing', 'dancing', 'match', 'US', 'boys', 'co', 'credit', 'Italian', 'visual', 'cover', 'successful', 'World', 'clever', 'concept', 'kills', 'positive', 'Great', 'recent', 'appreciate', 'biggest', 'focus', 'cartoon', 'speak', 'language', 'value', 'portrayal', 'German', 'spend', 'depth', 'Good', 'incredible', 'runs', 'store', 'Tony', 'choice', 'former', 'younger', 'House', 'common', 'violent', 'amount', 'control', 'exciting', 'singing', 'died', 'following', '90', 'escape', 'effective', 'amusing', 'compared', 'water', 'Night', 'bizarre', 'showed', 'Dead', 'apart', 'nt', 'Movie', 'adult', 'fire', 'follows', 'sweet', 'win', 'impressive', '8', 'chemistry', 'fit', 'solid', 'suddenly', 'Best', 'considered', 'respect', 'decide', 'fi', 'office', 'avoid', 'books', 'makers', 'gun', 'otherwise', 'animated', 'revenge', 'Black', 'slasher', 'trouble', 'culture', 'barely', 'changed', 'consider', 'hair', 'situations', 'baby', 'secret', 'won', '7', 'party', 'producers', 'trash', 'failed', 'studio', 'Smith', 'accent', 'longer', 'pointless', 'Let', 'likes', 'shooting', 'honest', 'walk', '15', 'trip', 'involving', 'values', 'disturbing', 'questions', 'sci', 'Steve', 'fake', 'leaving', 'tough', 'Jim', 'college', 'adventure', 'audiences', 'impossible', 'sick', 'bought', 'cult', 'heavy', 'state', 'City', 'London', 'charming', 'doctor', 'band', 'computer', 'rated', 'starring', 'images', 'ability', 'meaning', 'Big', 'Perhaps', 'anti', 'awesome', 'return', 'rock', 'earth', 'Stewart', 'appearance', 'basic', 'literally', 'normal', 'immediately', 'cold', 'explain', 'company', 'ultimately', 'Harry', 'Director', 'conclusion', 'prison', 'touch', 'utterly', 'appeal', 'aspect', 'stick', 'Sam', 'adaptation', 'considering', 'red', 'standard', 'oh', 'pathetic', 'rare', 'somewhere', 'Another', 'genius', 'glad', 'week', 'purpose', 'sitting', 'cause', 'drawn', 'thinks', 'fear', 'neither', 'humour', 'generally', 'twists', 'Earth', 'managed', 'military', 'pick', 'terms', 'Love', 'comedies', 'loud', 'OF', 'garbage', 'sexy', 'added', 'catch', 'Charlie', 'likely', 'magic', 'natural', 'subtle', '%', 'Kelly', 'fully', 'motion', 'shoot', 'project', 'tone', 'spirit', 'street', '100', 'People', 'ex', 'mood', 'complex', 'narrative', 'post', 'surprisingly', 'touching', 'force', 'remains', 'themes', 'okay', 'zombies', 'equally', 'taste', 'terrific', '/>All', '/>My', 'Only', 'constantly', 'Still', 'key', 'science', 'unbelievable', 'Frank', 'drive', 'issues', 'plus', 'nowhere', 'victim', '9', 'fair', 'innocent', 'presented', 'Every', 'Very', 'beautifully', 'cinematic', 'excuse', 'thrown', '70', 'presence', 'knowing', 'historical', 'pieces', 'brain', 'developed', 'door', 'impression', 'marriage', 'scenery', 'Though', 'Where', 'climax', 'hoping', 'painful', 'century', 'costumes', 'laughable', 'pass', 'date', 'super', 'Chris', 'Christopher', 'Film', 'finish', 'stands', 'Because', 'animals', 'photography', 'slowly', 'Charles', 'Paris', 'details', 'places', 'unlike', 'aspects', 'disappointing', 'sent', '/>One', 'manner', 'drug', 'held', 'outstanding', 'charm', 'dreams', 'exception', 'feelings', 'mistake', 'mysterious', 'numbers', 'walking', '50', 'Indian', 'stunning', 'alive', 'lovely', 'Nothing', 'Rock', 'contains', 'track', 'Henry', 'Jones', 'boyfriend', 'suppose', '6', 'Allen', 'Batman', 'names', 'support', 'building', 'filming', 'soldiers', 'expectations', 'fiction', 'noir', 'opportunity', 'silent', 'South', 'Two', 'acts', 'intended', 'changes', 'likable', 'puts', 'cat', 'lived', 'tired', 'Bruce', 'Little', 'Watch', 'emotions', 'include', 'producer', 'recommended', 'suggest', 'brief', 'disappointment', 'emotion', 'gang', 'bother', 'edge', 'loves', 'smart', 'government', 'pictures', 'soul', 'De', 'compelling', 'element', 'mainly', 'Sure', 'critics', 'detective', 'fascinating', 'appeared', 'available', 'lover', 'minor', 'Will', 'bar', 'fellow', 'camp', 'pain', 'Christian', 'serial', 'Young', 'attack', 'bed', 'western', 'dies', 'falling', 'fresh', 'lacks', 'spot', 'approach', 'difference', 'image', 'followed', 'journey', 'confused', 'ride', 'share', 'student', 'happening', 'law', 'train', 'Yet', 'dad', 'mad', 'Jerry', 'actresses', 'mix', 'offer', 'trailer', '\\x85 ', 'helps', 'proves', 'West', 'adults', 'moral', 'Mr', 'god', 'merely', 'relationships', 'road', 'victims', 'Americans', 'naked', 'shock', 'Martin', 'delivers', 'laughed', 'lighting', 'II', 'confusing', 'students', 'wondering', 'content', 'event', 'gorgeous', 'mediocre', 'provides', 'rape', 'sub', 'creative', 'direct', 'paid', 'throw', 'worthy', 'Billy', 'brothers', 'color', 'imagination', 'system', 'negative', 'Arthur', 'addition', 'random', 'Once', 'Red', 'ahead', 'impressed', 'nobody', 'offers', 'putting', 'aside', 'chase', 'childhood', 'latter', 'surely', 'IS', 'becoming', 'flicks', 'porn', 'Davis', 'boss', 'forgotten', 'funniest', 'notice', 'step', 'tragedy', 'tragic', 'winning', 'thoroughly', 'attractive', 'central', '=', 'fell', 'pull', '40', 'Van', 'answer', 'double', 'gem', 'million', 'reminded', 'sadly', 'stuck', 'Alan', 'flaws', 'island', 'thanks', 'Story', 'inspired', 'opera', 'seemingly', 'standards', 'Overall', 'cliché', 'ghost', 'murders', 'adds', 'de', 'forever', 'ship', 'Brian', 'Day', 'Williams', 'turning', 'honestly', 'supposedly', 'detail', 'plan', 'rented', 'wise', 'giant', 'intense', 'twice', 'wall', 'Despite', 'artistic', 'asks', 'six', 'Jean', 'absolute', 'describe', 'justice', 'onto', 'picked', 'planet', 'ready', 'Chinese', 'Jackson', 'length', 'personality', 'race', 'artist', 'fashion', 'finding', 'folks', 'industry', 'information', 'location', 'nasty', 'redeeming', 'shocking', 'afraid', 'lose', 'speaking', 'Both', 'Mark', 'filmmaker', 'hospital', 'scientist', 'struggle', 'AND', 'affair', 'deliver', 'ground', 'led', 'quick', 'Many', 'apartment', 'professional', 'wearing', 'Did', 'White', 'design', 'extreme', 'member', 'area', '/>Overall', 'Danny', 'allowed', 'cry', 'faces', 'helped', 'willing', 'Life', 'holes', 'moved', 'Too', 'build', 'favourite', 'flying', 'includes', '.....', 'clothes', 'damn', 'deeply', 'seconds', 'beat', 'began', 'realized', 'Ray', 'angry', 'anymore', 'bottom', 'comedic', 'impact', 'Anyway', 'hotel', 'teen', 'master', 'mouth', 'collection', 'introduced', 'loving', 'wonderfully', 'Taylor', 'energy', 'everybody', 'phone', 'ugly', 'wooden', 'carry', 'drugs', 'martial', 'vampire', 'Douglas', 'Stephen', 'apparent', 'born', 'epic', 'intelligence', 'necessary', 'thus', 'suicide', 'Bad', 'Jason', 'Other', 'Their', 'extra', 'food', 'provide', 'sight', 'thin', 'listen', 'religious', 'time.<br', 'accident', 'continue', 'land', 'mental', 'plane', 'teacher', '/>For', 'superior', 'dying', 'physical', 'engaging', 'technical', 'Eddie', 'Johnny', 'accept', 'personally', 'pleasure', 'teenage', 'unusual', '\\x85', '#', 'Al', 'Andy', 'Don', 'Russian', 'commentary', 'paced', 'scared', 'tears', 'actions', 'limited', 'remarkable', 'holds', 'humans', 'sleep', 'Fred', 'Tim', 'Ford', 'Keaton', 'allow', 'brutal', 'compare', 'disaster', 'finished', 'independent', 'lets', 'mom', 'agent', 'bits', 'mark', 'pop', 'whatsoever', 'wild', 'Hitler', 'Joan', 'Kate', 'asked', 'soft', 'Adam', 'Miss', 'criminal', 'intriguing', 'process', 'station', 'surprising', 'wanting', 'anywhere', 'creature', 'suspect', 'unnecessary', 'desperate', 'news', 'rarely', 'sat', 'vision', 'woods', 'CGI', 'Ed', 'Jeff', 'reminds', 'rip', 'search', 'Everything', 'Horror', 'Was', 'heroes', 'memory', 'absurd', 'arts', 'club', 'gotten', 'instance', 'pacing', 'England', 'Please', 'exist', 'jump', 'pilot', 'Which', 'creating', 'deserve', 'grade', 'hidden', '\"<br', 'Since', 'capture', 'cops', 'hated', 'player', 'Lady', 'Shakespeare', 'accurate', 'clichés', 'heroine', 'watchable', 'Ms.', 'constant', 'fights', 'issue', '_', 'anybody', 'desire', 'explanation', 'media', 'players', 'smile', 'blame', 'cross', 'deserved', 'heads', 'ill', 'lovers', 'plots', 'treat', 'Ann', 'Before', 'nicely', 'Having', 'Jesus', 'count', 'toward', 'European', 'Kevin', 'animal', 'channel', 'drunk', 'knowledge', 'mixed', 'responsible', '70s', 'Japan', 'VHS', 'church', 'returns', '/>Now', '/>When', 'Me', 'Spanish', 'aware', 'community', 'explained', 'growing', 'hopes', 'pulled', 'record', '80s', 'hurt', 'met', 'quiet', 'treated', 'Go', 'Nick', 'Superman', 'cars', 'fail', 'friendship', 'manage', 'torture', 'Dark', 'Everyone', 'Lewis', 'floor', 'games', 'nonsense', 'suit', 'twenty', 'Freddy', 'Those', 'humanity', 'loose', 'loss', 'partner', 'understanding', 'Tarzan', 'army', 'noticed', 'terribly', 'bloody', 'hits', 'lies', 'saved', 'villains', 'author', 'included', 'memories', 'months', 'soldier', 'cable', 'dealing', 'discover', 'discovered', 'eating', 'lacking', 'Jimmy', 'Lynch', 'Simon', 'bland', 'conflict', 'dangerous', 'keeping', 'portray', 'prove', '12', 'Morgan', 'dated', 'delightful', 'guns', 'loses', 'pre', 'unknown', 'Washington', 'award', 'driving', 'finest', 'numerous', 'pretentious', 'realism', 'regular', 'sign', 'skills', 'talents', '60', 'Santa', 'locations', 'passion', 'psychological', 'reviewers', 'Blood', 'Mike', 'alien', 'bigger', 'opposite', 'visit', 'breaks', 'bright', 'concerned', 'featuring', 'humorous', 'kinda', 'machine', 'opens', 'perspective', 'unfunny', 'Dick', 'See', 'Street', 'continues', 'cuts', 'deals', 'gags', 'kick', 'owner', 'received', 'soap', 'starting', 'theatre', 'traditional', 'Anthony', 'behavior', 'edited', 'horse', 'yeah', 'captured', 'empty', 'joy', 'mine', 'ordinary', 'satire', 'wide', 'youth', '/>To', 'Albert', 'Show', 'murdered', 'originally', 'African', 'Gary', 'Gene', 'High', 'Jennifer', 'Sean', 'debut', 'results', 'Bob', 'Eric', 'Lord', 'advice', 'below', 'calls', 'context', 'current', 'faith', 'genuine', 'remembered', 'sucks', 'ladies', 'ups', 'Death', 'THIS', 'cameo', 'grew', 'grown', 'learned', 'somebody', '/>While', 'Harris', 'Howard', 'Luke', 'Thomas', 'blue', 'forces', 'genuinely', 'sing', 'allows', 'finale', 'gangster', 'proved', 'revealed', 'rubbish', 'visuals', 'core', 'summer', 'versions', 'X', 'awkward', 'existence', 'na', 'overly', 'witty', \"/>I'm\", 'Anna', 'Kong', 'ass', 'develop', 'eat', 'officer', 'reach', 'steal', 'therefore', 'passed', 'roll', 'shallow', 'types', '/>That', 'decade', 'formula', 'higher', 'radio', 'reaction', 'sheer', 'study', 'suffering', 'unable', 'Are', 'parody', 'segment', 'singer', 'site', 'spectacular', 'them.<br', 'unexpected', 'Cage', 'discovers', 'efforts', 'favor', 'Anne', 'Stone', 'Welles', 'brilliantly', 'creates', 'delivered', 'gon', 'leader', 'program', 'references', 'strength', 'trust', 'Marie', 'screaming', 'wedding', 'connection', 'executed', 'frame', 'majority', 'mid', 'powers', 'stereotypes', 'survive', 'travel', 'Last', 'Sinatra', 'blind', 'curious', 'dimensional', 'relief', 'technology', 'caused', 'fault', 'lesson', 'protagonist', 'relate', 'sake', 'seven', 'Academy', 'Wow', 'board', 'built', 'corny', 'driven', 'pair', 'Barbara', 'Broadway', 'Can', 'Dan', 'Okay', 'Robin', 'bank', 'blonde', 'emotionally', 'failure', 'monsters', 'morning', 'ultimate', 'Fox', 'Men', 'Time', 'Wars', 'comparison', 'crappy', 'families', 'painfully', 'Gordon', 'fate', 'occasionally', 'window', 'wit', 'clean', 'flashbacks', 'graphic', 'gratuitous', 'logic', 'meeting', 'sell', 'Wayne', 'aged', 'combination', 'commercial', 'dressed', 'fill', 'gold', 'luck', 'obsessed', 'vehicle', 'Victoria', 'assume', 'described', 'gory', 'pleasant', 'sucked', '11', 'Western', 'believes', 'fat', 'produce', 'ran', 'range', 'ring', 'send', 'standing', 'stock', 'treatment', '/>However', 'France', 'Steven', 'laughter', 'magnificent', 'portrays', 'reviewer', 'Asian', 'Parker', 'asking', 'attitude', 'chosen', 'dreadful', 'identity', 'individual', 'learns', 'lucky', 'tape', 'Jr.', 'appealing', 'bet', 'broken', 'capable', 'essentially', 'excited', 'involves', 'levels', 'model', 'practically', 'proper', 'Joseph', 'decision', 'dry', 'entertained', 'grow', 'largely', 'sympathetic', 'underrated', 'utter', 'Roy', 'Woody', 'ages', 'handsome', 'par', 'portraying', 'religion', 'stopped', 'Bond', 'Canadian', 'Grant', 'Jackie', 'Prince', 'choose', 'hearted', 'ruined', 'warm', 'Daniel', 'Victor', 'boat', 'contrived', 'endless', 'foreign', 'irritating', 'normally', 'product', 'whilst', '1/2', 'La', 'Lost', 'Really', 'claim', 'desert', 'exploitation', 'feet', 'seat', 'shop', 'thank', 'theaters', 'Cinderella', 'IT', 'ancient', 'appropriate', 'insane', 'unrealistic', 'Anderson', 'Moore', 'Part', 'contrast', 'dubbed', 'evidence', 'hey', 'seasons', 'Alex', 'Captain', 'Halloween', 'Nancy', 'THAT', 'UK', 'depressing', 'hearing', 'safe', 'scare', 'Louis', 'Matt', 'chick', 'naive', 'saving', 'sports', 'streets', 'tend', 'theatrical', 'visually', 'whenever', 'zero', 'Trek', 'captures', 'embarrassing', 'fits', 'marry', 'nominated', 'round', 'talks', 'thoughts', 'village', '/>Then', 'Brown', 'Germany', 'cost', 'destroy', 'facts', 'field', 'flesh', 'judge', 'relatively', 'research', 'voices', 'warning', 'Ryan', 'fame', 'mission', 'sequels', 'walks', 'ball', 'convinced', 'crowd', 'lousy', 'rescue', 'Girl', 'Park', 'Patrick', 'Walter', 'cares', 'foot', 'spoil', 'steals', '10/10', 'contemporary', 'depicted', 'disgusting', 'losing', 'strongly', 'substance', 'teenager', 'ALL', 'Europe', 'asleep', 'b', 'circumstances', 'costs', 'covered', 'generation', 'insult', 'satisfying', 'Anyone', 'Oliver', 'Saturday', 'U.S.', 'Watching', 'amateur', 'handled', 'holding', 'inner', 'paper', 'remain', 'Africa', 'Powell', 'bear', 'clue', 'excitement', 'matters', 'provided', 'teenagers', '/>Also', 'Australian', 'Evil', 'Hitchcock', 'Murphy', 'Plus', 'R', 'Texas', 'Wood', 'anime', 'bringing', 'cash', 'initial', 'liners', 'pile', 'test', 'virtually', 'Russell', 'amateurish', 'bomb', 'mini', 'touches', 'viewed', 'More', 'bodies', 'correct', 'dirty', 'fare', 'football', 'horribly', 'i.e.', 'offensive', 'shocked', 'structure', 'sudden']\n",
      "2502\n",
      "<class 'list'>\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.4180,  0.2497, -0.4124,  ..., -0.1841, -0.1151, -0.7858],\n",
      "        ...,\n",
      "        [ 0.2337, -0.7152, -0.1912,  ...,  0.1908,  0.3518, -0.0332],\n",
      "        [ 0.9054,  0.5484, -0.2942,  ..., -0.2478,  0.0399, -0.2427],\n",
      "        [ 0.6436,  0.0540,  0.0944,  ...,  0.1137,  0.3243,  0.1347]])\n",
      "2502\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos)\n",
    "print(len(TEXT.vocab.itos))\n",
    "print(type(TEXT.vocab.itos))\n",
    "print(TEXT.vocab.vectors)\n",
    "print(len(TEXT.vocab.vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.io.gfile' has no attribute 'get_filesystem'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-200330e2b3a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/packt/venv/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36madd_embedding\u001b[0;34m(self, mat, metadata, label_img, global_step, tag, metadata_header)\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_logdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_filesystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.io.gfile' has no attribute 'get_filesystem'"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "writer.add_embedding(TEXT.vocab.vectors, [x.encode('utf-8') for x in TEXT.vocab.itos])\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorboard as tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "writer.add_embedding(TEXT.vocab.vectors, [x.encode('utf-8') for x in TEXT.vocab.itos])\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        return self.fc(hidden.squeeze(0))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_dim=len(TEXT.vocab), embedding_dim=50, hidden_dim=256, output_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, test_iterator = data.BucketIterator.splits((train_data, test_data), batch_size=64, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 647,  156,   54,  ..., 2208,   54,  149],\n",
      "        [  13,   57,   19,  ...,   39,    0,  163],\n",
      "        [   0,   30,  998,  ...,    0,   28,  970],\n",
      "        ...,\n",
      "        [   2,    1,    1,  ...,    1,    1,    1],\n",
      "        [   0,    1,    1,  ...,    1,    1,    1],\n",
      "        [  29,    1,    1,  ...,    1,    1,    1]])\n",
      "tensor([0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 1., 1., 0.])\n",
      "tensor([[ 149,    2,   16,  ...,   66,    0,   11],\n",
      "        [1267, 1986,    0,  ...,   19,  464,  469],\n",
      "        [ 758,    7,    0,  ...,   38,    7,  143],\n",
      "        ...,\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1]])\n",
      "tensor([1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_iterator):\n",
    "    if i < 2:\n",
    "        print(batch.text)\n",
    "        print(batch.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "writer.add_graph(model, batch.text)\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, test_iterator = data.BucketIterator.splits((train_data, test_data), batch_size=64, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "\n",
    "model = RNN(input_dim=len(TEXT.vocab), embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 399999/400000 [00:19<00:00, 20464.51it/s]\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(train_data, max_size=2500, vectors=torchtext.vocab.GloVe(name='6B', dim=embedding_dim))\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(2502, 100)\n",
       "  (rnn): RNN(100, 256)\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(y_true, predict):\n",
    "    rounded_predicts = torch.round(torch.sigmoid(predict))\n",
    "    correct = (rounded_predicts==y_true).float()\n",
    "    return correct.sum() / len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretraioned_embeddings = TEXT.vocab.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2502, 100])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretraioned_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [-0.1699,  0.1631,  0.6325,  ..., -0.0244, -0.5670,  0.1749],\n",
       "        [-0.1435,  0.6606, -0.0788,  ..., -1.6433,  0.6658,  0.1726],\n",
       "        [ 0.4098, -0.6922,  0.6605,  ..., -0.3771, -0.0812, -0.4148]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data.copy_(pretraioned_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.6960257462528355, Acc: 0.5036604860249687\n",
      "Epoch: 1, Loss: 0.6986272444810404, Acc: 0.49660326086956524\n",
      "Epoch: 2, Loss: 0.697589741795874, Acc: 0.4975143862349908\n",
      "Epoch: 3, Loss: 0.696794686872331, Acc: 0.4978420716112532\n",
      "Epoch: 4, Loss: 0.6957235560392785, Acc: 0.5025575447570333\n",
      "Epoch: 5, Loss: 0.6971365951211251, Acc: 0.5014146419284898\n",
      "Epoch: 6, Loss: 0.6963967687028754, Acc: 0.49781010233227857\n",
      "Epoch: 7, Loss: 0.6964495980831058, Acc: 0.5063778772530958\n",
      "Epoch: 8, Loss: 0.6971018225945476, Acc: 0.5024616369201095\n",
      "Epoch: 9, Loss: 0.6964242773897508, Acc: 0.49792998724276455\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)   \n",
    "criterion = criterion.to(device)  \n",
    "\n",
    "\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in train_iterator:\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(batch.text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(outputs, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(batch.label, outputs)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    train_loss = epoch_loss / len(train_iterator)\n",
    "    train_acc = epoch_acc / len(train_iterator)\n",
    "    \n",
    "#     writer.add_scalar(\"Loss\", loss.item(), epoch)\n",
    "    print(f\"Epoch: {epoch}, Loss: {train_loss}, Acc: {train_acc}\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for batch in iterator:       \n",
    "        outputs = model(batch.text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(outputs, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(batch.label, outputs)\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return  epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6949618602042917, 0.500815217452281)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "writer.add_hparams({\"Embedding Dim\": embedding_dim, \"Hidden dim\": hidden_dim}, {\"hparam/loss\": test_loss, \"hparam/accuracy\": test_acc})\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
