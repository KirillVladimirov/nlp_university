{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ноутбуки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_data_preprocessing_for_classification\n",
    "\n",
    "Подготовка датасета твитов для дальнейшей работы с задачей классификации.\n",
    "В первоначальном варианте удалялись стоп-слова, поунктуация, гипперссылки и упоминания пользователей, проводилась лемматизация.\n",
    "Такой пайплайн я использовал ранее для обработки \"обычных\" текстов. Данный вариант предварительной обработки удалял почти все содержимое твита. Классификация линейными моделями и моделями pytorch давала f1 около 0.7.\n",
    "\n",
    "Затем я использовал вариант предобработки, описаный в работах \"Анализируем тональность текстов с помощью Fast.ai\" и \"Sentiment Analysis of Posts and Comments in the Accounts of Russian Politicians on the Social Network\".\n",
    "Я оставил стоп-слова и пунктуацию, а ссылки, хэштеги и упоминания пользователей заменил на теги url, hash и at_user.\n",
    "\n",
    "В дальнейшем можно добавить анализ пунктуации и распознование смайликов и замену их на теги соответствующих смайлов. Это уменьшит \"шум\", создоваемый черезмерным употреблением символов пунктуации. Для простоты, я не стал удалять знаки пунктуации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02_sklearn_pipeline_linear_classifier\n",
    "\n",
    "Использовал стандартный пайплайн sklearn для классификации текстов с использование tf-idf и логистической регресси. Параметры подбирались перебором по сетке.\n",
    "Для первого варианте предобработки f1 = 0.735, для второго f1 = 0.765"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03_pytorch_pipeline_linear_classifier_v1 и 03_pytorch_pipeline_linear_classifier_v2\n",
    "\n",
    "Реализовал логистическую регрессию на pytorch. Ноутбуки были сделаны для разных версий предобработки твитов. На вход моделям текст подавался преобразованный в tf-idf пайплайном sklearn. Результат приблизительно одинаковый f1 = 0.73. Модели очень долго обучались. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04_prepare_data_for_pytorch\n",
    "\n",
    "Здесь разобран способ подготовки текстовых данных в модели pytorch, работающие с плотным представлением слов embeddings.\n",
    "Во всех моделях использовал предобученные веса word2vec.\n",
    "\n",
    "Далее все модели работают с последней версией предобработки текстов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05_convolutional_sentiment_analysis\n",
    "\n",
    "Классификация текстов с использованием слоев одномерной свертки. f1 = 0.9938. Очень большой вклад вносит оставленная пунктуация (около 20%). На втором месте по вкладу в результат - оставленные стоп-слова (около 5%). \n",
    "\n",
    "Последовательность эмбедингов обрабатывается независимо 3ми слоями свертки с размерами фильтров 2 и 3, результат конкатинируется и проходит через линейные слои.\n",
    "Гиперпараметры модели - количество слоев свертки и их размер. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06_recurrent_sentiment_analysis\n",
    "\n",
    "Классификация текстов с использованием 2х слойной 2у направленной LSTM. f1 = 0.9949."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07_data_preprocessing_and_prepare_for_regression\n",
    "\n",
    "Показан процесс предобработки текстов твитов и подготовка датасета для работы с моделями pytorch для решения задачи регресси - предсказывания количества ретвитов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08_retweet_regression\n",
    "\n",
    "Для решения задачи предсказания количества ретвитов использовался подход, описанный в статье \"Retweet Wars: Tweet Popularity Prediction via Dynamic Multimodal Regression\". Исползуется мульти модальная модель. Для обработки текстов взята модель из ноутбука \"05_convolutional_sentiment_analysis\". Результат обработки тектстов попадает на линейный слой, куда также приходят данные с профиля пользователя.\n",
    "\n",
    "MAE = 10.96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09_retweet_regression_from_lstm\n",
    "\n",
    "Еще один вариант решения задачи регресси. В качестве сети обработки текстов используется модель из ноутбука \"06_recurrent_sentiment_analysis\".\n",
    "\n",
    "MAE = 10.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10_bert_classification_with_gru и 11_retweet_regression_with_bert\n",
    "\n",
    "В этих ноутбуках приведены решения задач и использование предобученного BERT от DeepPavlov. BERT используется для генерации эмбедингов.\n",
    "\n",
    "Для классификации f1 = 0.9912 при обучении в течении 6 эпох.\n",
    "\n",
    "Для регресси MAE = 12.1 при обучении в течении 3 эпох.\n",
    "\n",
    "Обучение проходило с замороженными весами BERT без дообучении на корпусе твитов. Поэтому решения, основанные на BERT, имеют большое поль для доработак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
